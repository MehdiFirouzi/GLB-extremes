{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e17999-e0bf-4f1a-8201-165c0e66b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking the EMDNA, Extracting prcp and organizing the ensembles per year 1989-2018\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# --- USER SETTINGS ---\n",
    "\n",
    "# Define the extended bounding box\n",
    "min_lon, max_lon = -93, -74.5   # Desired longitude limits\n",
    "max_lat, min_lat = 50.5, 40.0   # Desired latitude limits\n",
    "\n",
    "# Main input folder containing year-based subfolders (e.g., 1989, 1990, ..., 2018)\n",
    "main_input_folder = r\"Z:\\DATA\\EMDNAdata\"\n",
    "\n",
    "# Base output folder where each ensemble subfolder (e.g., \"001\", \"002\", etc.) will be created\n",
    "output_folder = r\"D:\\PhD\\GLB\\EMDNA full\"\n",
    "\n",
    "# --- SCRIPT BEGINS ---\n",
    "\n",
    "print(\"Extended bounding box:\")\n",
    "print(f\"  lon: {min_lon} to {max_lon}\")\n",
    "print(f\"  lat: {max_lat} to {min_lat}\\n\")\n",
    "\n",
    "# Gather year subfolders (1989, 1990, 1991, ..., 2018)\n",
    "year_folders = [\n",
    "    os.path.join(main_input_folder, d)\n",
    "    for d in os.listdir(main_input_folder)\n",
    "    if os.path.isdir(os.path.join(main_input_folder, d))\n",
    "]\n",
    "\n",
    "for year_folder in year_folders:\n",
    "    year_name = os.path.basename(year_folder)\n",
    "    print(f\"Processing year folder: {year_folder}\")\n",
    "\n",
    "    # Collect all .nc4 files in this year folder\n",
    "    nc_files = glob.glob(os.path.join(year_folder, \"*.nc4\"))\n",
    "    if not nc_files:\n",
    "        print(f\"  No .nc4 files found in {year_folder}\")\n",
    "        continue\n",
    "\n",
    "    for file_path in nc_files:\n",
    "        base_name = os.path.basename(file_path)\n",
    "\n",
    "        # Skip any mean or spread files\n",
    "        if \"mean.nc4\" in base_name.lower() or \"spread.nc4\" in base_name.lower():\n",
    "            print(f\"  Skipping file (mean/spread): {base_name}\")\n",
    "            continue\n",
    "\n",
    "        # Parse the ensemble number from the filename\n",
    "        # Example filename: EMDNA_1989.001.nc4 -> ensemble_str = \"001\"\n",
    "        # This assumes the pattern: EMDNA_YYYY.XXX.nc4\n",
    "        parts = base_name.rsplit('.', 2)\n",
    "        if len(parts) != 3:\n",
    "            print(f\"  WARNING: Unexpected filename format; skipping {base_name}\")\n",
    "            continue\n",
    "        ensemble_str = parts[1]  # \"001\", \"002\", etc.\n",
    "\n",
    "        print(f\"  Processing file: {base_name} (Ensemble {ensemble_str})\")\n",
    "\n",
    "        # Open the dataset\n",
    "        ds = xr.open_dataset(file_path)\n",
    "\n",
    "        # Rename dimensions: \"x\" -> \"lon\" and \"y\" -> \"lat\"\n",
    "        if \"x\" in ds.dims and \"y\" in ds.dims:\n",
    "            ds = ds.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "\n",
    "        # Assign coordinate values for \"lon\" and \"lat\" from \"longitude\"/\"latitude\"\n",
    "        if \"longitude\" in ds.variables and \"latitude\" in ds.variables:\n",
    "            ds = ds.assign_coords(lon=ds[\"longitude\"], lat=ds[\"latitude\"])\n",
    "            ds = ds.drop_vars([\"longitude\", \"latitude\"])\n",
    "\n",
    "        # Subset/mask to the bounding box\n",
    "        ds_masked = ds.sel(lon=slice(min_lon, max_lon),\n",
    "                           lat=slice(max_lat, min_lat))\n",
    "\n",
    "        # Extract only the prcp variable (if present)\n",
    "        if \"prcp\" not in ds_masked.data_vars:\n",
    "            print(f\"    No 'prcp' variable found in {base_name}, skipping.\")\n",
    "            ds_masked.close()\n",
    "            ds.close()\n",
    "            continue\n",
    "        ds_prcp = ds_masked[[\"prcp\"]]\n",
    "\n",
    "        # Create the output subfolder for this ensemble number\n",
    "        # e.g., D:\\PhD\\GLB\\EMDNA full\\001\n",
    "        ensemble_folder = os.path.join(output_folder, ensemble_str)\n",
    "        os.makedirs(ensemble_folder, exist_ok=True)\n",
    "\n",
    "        # Construct output file name: EMDNA_1989.001_masked_prcp.nc4\n",
    "        output_name = base_name.replace(\".nc4\", \"_masked_prcp.nc4\")\n",
    "        output_file = os.path.join(ensemble_folder, output_name)\n",
    "\n",
    "        # Save the prcp dataset\n",
    "        ds_prcp.to_netcdf(output_file)\n",
    "\n",
    "        # Close datasets\n",
    "        ds_prcp.close()\n",
    "        ds_masked.close()\n",
    "        ds.close()\n",
    "\n",
    "        print(f\"    Saved prcp file to: {output_file}\")\n",
    "\n",
    "print(\"\\nAll folders processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f71f5-3cd4-4cfd-87c4-b262e0f43316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "# --------------------- USER SETTINGS ---------------------\n",
    "base_folder = r\"D:\\PhD\\GLB\\EMDNA full\"  # Path containing subfolders named 001..100\n",
    "\n",
    "def parse_ensemble_folder(folder_name):\n",
    "    \"\"\"\n",
    "    Convert a folder name like '001' to integer 1, '010' to 10, etc.\n",
    "    Returns None if folder_name is not a valid integer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(folder_name)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Loop through each subfolder (001..100), find all .nc4 files,\n",
    "# manually open them, and concatenate along the 'time' dimension.\n",
    "# Then save the merged dataset as a single NetCDF file.\n",
    "# ---------------------------------------------------------\n",
    "for folder_name in sorted(os.listdir(base_folder)):\n",
    "    folder_path = os.path.join(base_folder, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        # Convert folder name like '001' -> 1\n",
    "        ens_num = parse_ensemble_folder(folder_name)\n",
    "        # We only proceed if it's a valid ensemble number\n",
    "        if ens_num is not None:\n",
    "            # Gather the 30 yearly .nc4 files in this folder\n",
    "            nc_files = sorted(glob.glob(os.path.join(folder_path, \"*.nc4\")))\n",
    "            \n",
    "            if not nc_files:\n",
    "                print(f\"No .nc4 files found in folder: {folder_name}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Open each year's NetCDF and store in a list\n",
    "            ds_list = []\n",
    "            for f in nc_files:\n",
    "                ds_list.append(xr.open_dataset(f))\n",
    "            \n",
    "            # Concatenate them along the 'time' dimension\n",
    "            ds_merged = xr.concat(ds_list, dim=\"time\")\n",
    "            \n",
    "            # Close the individual datasets now that we've merged\n",
    "            for ds in ds_list:\n",
    "                ds.close()\n",
    "            \n",
    "            # Construct output file name, e.g. \"merger_1_1989-2018_prcp.nc\"\n",
    "            # or \"merger_001_1989-2018_prcp.nc\" – whichever format you prefer\n",
    "            output_file = os.path.join(\n",
    "                folder_path,\n",
    "                f\"merged_{ens_num:03d}_1989-2018_prcp.nc\"\n",
    "            )\n",
    "            \n",
    "            # Save the merged dataset\n",
    "            ds_merged.to_netcdf(output_file)\n",
    "            ds_merged.close()\n",
    "            \n",
    "            print(f\"Merged {len(nc_files)} files into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf081115-dcda-4aff-a937-e21b5518edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for testing the 10 ensembles over 100 ensembles mean, variance and distribution with bootstrapping\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "# --------------------- 1) USER SETTINGS ---------------------\n",
    "base_folder = r\"D:\\PhD\\GLB\\EMDNA full\"  # top-level folder containing subfolders named 001..100\n",
    "\n",
    "# Full ensemble range (1..100)\n",
    "all_ensembles = list(range(1, 101))\n",
    "\n",
    "# Your chosen subset of 10 ensembles\n",
    "subset_ensembles = [1, 11, 21, 31, 41, 51, 61, 71, 81, 91]\n",
    "\n",
    "\n",
    "def parse_ensemble_folder(folder_name: str):\n",
    "    \"\"\"\n",
    "    Convert a folder name like '001' to integer 1, '010' to 10, etc.\n",
    "    Returns None if it's not a valid integer folder name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(folder_name)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_annual_means_for_ensemble(ensemble_folder: str, ens_str: str):\n",
    "    \"\"\"\n",
    "    1) Locates the merged NetCDF file named \"merged_<ens_str>_1989-2018_prcp.nc\" in this folder.\n",
    "    2) Opens it with xarray.\n",
    "    3) If 'time' is not datetime64, assign a DatetimeIndex from 1989-01-01 daily\n",
    "       for however many days are in 'time' (using ds.sizes['time']).\n",
    "    4) Compute domain-average precipitation (mean over lon & lat).\n",
    "    5) Resample to annual means using 'YS' (Year Start).\n",
    "    6) Return a 1D NumPy array (~30 values, one per year 1989-2018).\n",
    "    \"\"\"\n",
    "    # Example file name: merged_001_1989-2018_prcp.nc\n",
    "    merged_pattern = f\"merged_{ens_str}_1989-2018_prcp.nc\"\n",
    "    merged_file = os.path.join(ensemble_folder, merged_pattern)\n",
    "    \n",
    "    if not os.path.isfile(merged_file):\n",
    "        print(f\"  File not found: {merged_file}. Skipping ensemble {ens_str}.\")\n",
    "        return None\n",
    "    \n",
    "    ds = xr.open_dataset(merged_file)\n",
    "    \n",
    "    # Ensure 'time' is a daily DatetimeIndex, if not already\n",
    "    if not np.issubdtype(ds.time.dtype, np.datetime64):\n",
    "        n_time = ds.sizes['time']  # Future-proof method to get dimension length\n",
    "        new_time = pd.date_range(start=\"1989-01-01\", periods=n_time, freq='D')\n",
    "        ds = ds.assign_coords(time=new_time)\n",
    "\n",
    "    # Domain-average precipitation\n",
    "    ds_domain_mean = ds['prcp'].mean(dim=['lon', 'lat'])\n",
    "    \n",
    "    # Resample annually with 'YS' (year start) to avoid 'AS' deprecation warning\n",
    "    annual_means = ds_domain_mean.resample(time='YS').mean()\n",
    "    annual_means_values = annual_means.values\n",
    "    \n",
    "    ds.close()\n",
    "    return annual_means_values\n",
    "\n",
    "\n",
    "# --------------------- 2) GATHER DATA FOR EACH ENSEMBLE ---------------------\n",
    "ensemble_annual_means = {}  # key= ensemble int (1..100), value= array of ~30 annual means\n",
    "\n",
    "for folder_name in sorted(os.listdir(base_folder)):\n",
    "    folder_path = os.path.join(base_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        ens_num = parse_ensemble_folder(folder_name)\n",
    "        if ens_num is not None and ens_num in all_ensembles:\n",
    "            ens_str = f\"{ens_num:03d}\"\n",
    "            ann_means = get_annual_means_for_ensemble(folder_path, ens_str)\n",
    "            if ann_means is not None:\n",
    "                ensemble_annual_means[ens_num] = ann_means\n",
    "\n",
    "print(f\"\\nFound annual means for {len(ensemble_annual_means)} ensembles (out of 100).\")\n",
    "\n",
    "# --------------------- 3) BUILD FULL & SUBSET ARRAYS (ALL ANNUAL MEANS) ---------------------\n",
    "full_data = []\n",
    "for ens_num in sorted(all_ensembles):\n",
    "    if ens_num in ensemble_annual_means:\n",
    "        full_data.extend(ensemble_annual_means[ens_num])\n",
    "full_data = np.array(full_data)\n",
    "\n",
    "subset_data = []\n",
    "for ens_num in subset_ensembles:\n",
    "    if ens_num in ensemble_annual_means:\n",
    "        subset_data.extend(ensemble_annual_means[ens_num])\n",
    "subset_data = np.array(subset_data)\n",
    "\n",
    "print(\"Full set array shape (annual means):\", full_data.shape)\n",
    "print(\"Subset array shape (annual means):\", subset_data.shape)\n",
    "\n",
    "# --------------------- 4) T-TEST, LEVENE'S TEST, K–S TEST ---------------------\n",
    "t_stat, p_value_ttest = stats.ttest_ind(subset_data, full_data, equal_var=False)\n",
    "print(\"\\n== Two-sample t-test (compare means) ==\")\n",
    "print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "print(f\"  p-value:     {p_value_ttest:.6g}\")\n",
    "if p_value_ttest < 0.05:\n",
    "    print(\"  => Means are significantly different (p < 0.05).\")\n",
    "else:\n",
    "    print(\"  => No significant difference in means (p >= 0.05).\")\n",
    "\n",
    "W_stat, p_value_levene = stats.levene(subset_data, full_data, center='mean')\n",
    "print(\"\\n== Levene’s test (compare variances) ==\")\n",
    "print(f\"  W-statistic: {W_stat:.4f}\")\n",
    "print(f\"  p-value:     {p_value_levene:.6g}\")\n",
    "if p_value_levene < 0.05:\n",
    "    print(\"  => Variances differ significantly (p < 0.05).\")\n",
    "else:\n",
    "    print(\"  => No significant difference in variances (p >= 0.05).\")\n",
    "\n",
    "ks_stat, ks_p = stats.ks_2samp(subset_data, full_data)\n",
    "print(\"\\n== Two-sample K–S test (compare distributions) ==\")\n",
    "print(f\"  KS statistic: {ks_stat:.4f}\")\n",
    "print(f\"  p-value:      {ks_p:.6g}\")\n",
    "if ks_p < 0.05:\n",
    "    print(\"  => Distributions differ significantly (p < 0.05).\")\n",
    "else:\n",
    "    print(\"  => No significant difference in distributions (p >= 0.05).\")\n",
    "\n",
    "\n",
    "# --------------------- 5) BOOTSTRAPPING ---------------------\n",
    "# (A) Reduce each ensemble to a single 30-year mean => 1 value per ensemble\n",
    "ensemble_mean = {}\n",
    "for ens_num, ann_array in ensemble_annual_means.items():\n",
    "    ensemble_mean[ens_num] = ann_array.mean()\n",
    "\n",
    "# Build array of full set's ensemble-level means (length ≤ 100)\n",
    "all_ensemble_means = []\n",
    "for ens_num in sorted(all_ensembles):\n",
    "    if ens_num in ensemble_mean:\n",
    "        all_ensemble_means.append(ensemble_mean[ens_num])\n",
    "all_ensemble_means = np.array(all_ensemble_means)\n",
    "\n",
    "# Build array of subset's ensemble-level means (length ≤ 10)\n",
    "subset_ensemble_means = []\n",
    "for ens_num in subset_ensembles:\n",
    "    if ens_num in ensemble_mean:\n",
    "        subset_ensemble_means.append(ensemble_mean[ens_num])\n",
    "subset_ensemble_means = np.array(subset_ensemble_means)\n",
    "\n",
    "# Real subset's average = average of its 10 means\n",
    "real_subset_mean = subset_ensemble_means.mean()\n",
    "\n",
    "def bootstrap_test_ensemble_means(all_means, real_subset_mean, n_ensembles=10, n_boot=10000):\n",
    "    \"\"\"\n",
    "    Perform a bootstrap to see how typical 'real_subset_mean' is\n",
    "    compared to random draws of 'n_ensembles' from 'all_means'.\n",
    "\n",
    "    all_means: array of shape (N,) e.g. 100 ensemble-level means\n",
    "    real_subset_mean: float, the chosen subset's mean\n",
    "    n_ensembles: number of ensembles in each draw (10)\n",
    "    n_boot: number of bootstrap iterations (e.g., 10000)\n",
    "\n",
    "    Returns: (boot_means, p_value_two_sided)\n",
    "      - boot_means: array of shape (n_boot,) with the average for each draw\n",
    "      - p_value_two_sided: fraction of draws that are as extreme as 'real_subset_mean'\n",
    "                           in either tail (two-sided).\n",
    "    \"\"\"\n",
    "    N = len(all_means)\n",
    "    boot_means = np.zeros(n_boot, dtype=float)\n",
    "\n",
    "    for i in range(n_boot):\n",
    "        # Randomly pick 'n_ensembles' items WITH replacement\n",
    "        sample_indices = np.random.randint(0, N, size=n_ensembles)\n",
    "        sample_means = all_means[sample_indices]\n",
    "        boot_means[i] = sample_means.mean()\n",
    "\n",
    "    # Fraction of bootstrap means <= real_subset_mean\n",
    "    fraction_le = np.mean(boot_means <= real_subset_mean)\n",
    "    # Fraction of bootstrap means >= real_subset_mean\n",
    "    fraction_ge = np.mean(boot_means >= real_subset_mean)\n",
    "\n",
    "    # Two-sided test\n",
    "    p_two_sided = 2 * min(fraction_le, fraction_ge)\n",
    "    return boot_means, p_two_sided\n",
    "\n",
    "\n",
    "# Run bootstrap\n",
    "boot_means, p_val_boot = bootstrap_test_ensemble_means(\n",
    "    all_ensemble_means,\n",
    "    real_subset_mean,\n",
    "    n_ensembles=10,\n",
    "    n_boot=10000\n",
    ")\n",
    "\n",
    "print(\"\\n== BOOTSTRAP RESULTS (ensemble-level means) ==\")\n",
    "print(f\"  Subset of 10 average: {real_subset_mean:.4f}\")\n",
    "print(f\"  Two-sided p-value from bootstrap: {p_val_boot:.4f}\")\n",
    "if p_val_boot < 0.05:\n",
    "    print(\"  => The chosen 10-ensemble subset’s mean is unusual (outside ~95% range).\")\n",
    "else:\n",
    "    print(\"  => The chosen 10-ensemble subset’s mean is typical of a random 10-ensemble draw.\")\n",
    "\n",
    "print(\"\\nAll comparisons (including bootstrap) complete.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
