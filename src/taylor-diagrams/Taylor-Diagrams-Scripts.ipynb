{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1e604-e99a-4915-b6b5-3cf41d3afb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps and Taylor diagram for PRISM (PRCP)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "##############################################################################\n",
    "# 1. FILE PATHS\n",
    "##############################################################################\n",
    "nc_file       = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\PRISM_GLB_Precipitation\\daily_loop3\\prism_vs_stations_8Nearest_LWR_1991_2012.nc\"\n",
    "metrics_csv   = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\PRISM_GLB_Precipitation\\metrics3\\station_metrics_8Nearest_LWR_prism_1991_2012.csv\"\n",
    "physical_file = r\"D:\\PhD\\GLB\\Merged USA and CA\\Entire GLB\\filtered_stations_with_elevation.csv\"\n",
    "shapefile_path= r\"D:\\PhD\\GLB\\greatlakes_subbasins\\New folder\\Great_Lakes.shp\"\n",
    "lakes_shp     = r\"D:\\PhD\\GLB\\greatlakes_subbasins\\GLB_Water_Bodies\\Main_Lakes_GLB.shp\"\n",
    "target_crs    = \"EPSG:4326\"  \n",
    "output_dir    = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\PRISM_GLB_Precipitation\\Maps_and_Taylor3\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "##############################################################################\n",
    "# 2. LOAD NETCDF (RENAME DIMENSION) & METRICS CSV\n",
    "##############################################################################\n",
    "print(\"Loading prism vs Station NetCDF ...\")\n",
    "ds_raw = xr.open_dataset(nc_file)\n",
    "print(\"Original dims in NetCDF:\", ds_raw.dims)\n",
    "\n",
    "# Rename dimension \"variable\" -> \"station\"\n",
    "ds = ds_raw.rename({\"variable\": \"station\"})\n",
    "print(\"\\nAfter renaming => ds.dims:\", ds.dims)\n",
    "print(\"Data variables in NetCDF:\", list(ds.data_vars))\n",
    "\n",
    "print(\"\\nLoading station-level metrics from CSV ...\")\n",
    "df_metrics = pd.read_csv(metrics_csv)\n",
    "print(\"Loaded metrics CSV with columns:\", df_metrics.columns.tolist())\n",
    "\n",
    "# The code uses \"d\" for the Index of Agreement. If your CSV uses \"Index_of_Agreement\",\n",
    "# rename it to \"d\" so references to 'd' won't fail:\n",
    "if \"Index_of_Agreement\" in df_metrics.columns and \"d\" not in df_metrics.columns:\n",
    "    df_metrics = df_metrics.rename(columns={\"Index_of_Agreement\": \"d\"})\n",
    "\n",
    "##############################################################################\n",
    "# 3. LOAD & MERGE STATION COORDINATES\n",
    "##############################################################################\n",
    "print(\"\\nLoading station location info ...\")\n",
    "df_physical = pd.read_csv(physical_file)\n",
    "df_physical = df_physical.rename(columns={\n",
    "    \"NAME\": \"station_name\",\n",
    "    \"LATITUDE\": \"lat\",\n",
    "    \"LONGITUDE\": \"lon\",\n",
    "    \"Elevation\": \"elev\"\n",
    "})\n",
    "\n",
    "# Merge on station_name (assuming it matches)\n",
    "common_col = \"station_name\"\n",
    "if common_col not in df_metrics.columns:\n",
    "    print(f\"WARNING: {common_col} not in df_metrics. Aborting or adjust code.\")\n",
    "    # Might raise an error or do a different approach\n",
    "\n",
    "print(\"\\nMerging metrics with physical station coords ...\")\n",
    "df_merged = pd.merge(df_metrics, df_physical, how=\"inner\", on=common_col)\n",
    "print(f\"Merged shape: {df_merged.shape}\")\n",
    "print(\"Columns:\", df_merged.columns.tolist())\n",
    "\n",
    "##############################################################################\n",
    "# 4. BASIC CHECKS ON NETCDF\n",
    "##############################################################################\n",
    "time_dim = ds[\"time\"].size\n",
    "station_dim = ds[\"station\"].size\n",
    "print(f\"\\nNetCDF: # time steps = {time_dim}, # stations = {station_dim}\")\n",
    "time_min = ds[\"time\"].values.min()\n",
    "time_max = ds[\"time\"].values.max()\n",
    "print(\"Time range in NetCDF =>\", str(time_min), \"to\", str(time_max))\n",
    "\n",
    "##############################################################################\n",
    "# 5. LOAD GREAT LAKES SHAPEFILE\n",
    "##############################################################################\n",
    "print(\"\\nLoading Great Lakes shapefile ...\")\n",
    "gdf_lakes = gpd.read_file(shapefile_path)\n",
    "if gdf_lakes.crs is not None:\n",
    "    gdf_lakes = gdf_lakes.to_crs(target_crs)\n",
    "else:\n",
    "    gdf_lakes.crs = target_crs\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = gdf_lakes.total_bounds\n",
    "print(\"Great Lakes shapefile loaded. Bounds:\", (lon_min, lat_min, lon_max, lat_max))\n",
    "\n",
    "##############################################################################\n",
    "# 6. MAP STATISTICAL METRICS (MBE,RMSE,STD,CC,d) WITH “HOTSPOTS”\n",
    "##############################################################################\n",
    "metrics_list = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "titles_dict  = {\n",
    "    \"MBE\":  \"Mean Bias Error (MBE)\",\n",
    "    \"RMSE\": \"Root Mean Square Error (RMSE)\",\n",
    "    \"STD\":  \"Standard Deviation (STD)\",\n",
    "    \"CC\":   \"Correlation Coefficient (CC)\",\n",
    "    \"d\":    \"Index of Agreement (d)\"\n",
    "}\n",
    "\n",
    "print(\"\\nGenerating metric maps with hotspots ...\")\n",
    "\n",
    "for metric in metrics_list:\n",
    "    if metric not in df_merged.columns:\n",
    "        print(f\"Metric {metric} not found in df_merged. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Base map\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.4)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Plot the Great Lakes boundary\n",
    "    for geom in gdf_lakes.geometry:\n",
    "        ax.add_geometries([geom], ccrs.PlateCarree(), facecolor='none', edgecolor='blue', linewidth=1)\n",
    "\n",
    "    # Plot station metrics\n",
    "    sc = ax.scatter(df_merged[\"lon\"], df_merged[\"lat\"],\n",
    "                    c=df_merged[metric], cmap=\"viridis\", s=60, edgecolor=\"k\",\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    cb = plt.colorbar(sc, ax=ax, shrink=0.8, pad=0.02)\n",
    "    cb.set_label(metric, fontsize=12)\n",
    "\n",
    "    plt.title(f\"Spatial Distribution: {titles_dict.get(metric, metric)}\", fontsize=14)\n",
    "\n",
    "    # Identify hotspots\n",
    "    # For MBE, RMSE, STD => top 10%\n",
    "    # For CC, d => bottom 10%\n",
    "    vals = df_merged[metric].dropna().values\n",
    "    if metric in [\"MBE\",\"RMSE\",\"STD\"]:\n",
    "        thr = np.percentile(vals, 90)\n",
    "        hotspot = df_merged[metric] >= thr\n",
    "        label_txt = f\"Hotspot >= {thr:.2f}\"\n",
    "    else:\n",
    "        thr = np.percentile(vals, 10)\n",
    "        hotspot = df_merged[metric] <= thr\n",
    "        label_txt = f\"Hotspot <= {thr:.2f}\"\n",
    "\n",
    "    ax.scatter(df_merged.loc[hotspot,\"lon\"], df_merged.loc[hotspot,\"lat\"],\n",
    "               facecolors='none', edgecolors='red', s=90, linewidths=1.5,\n",
    "               transform=ccrs.PlateCarree(), label=label_txt)\n",
    "\n",
    "    # Add Lat/Lon gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.right_labels = False\n",
    "    gl.top_labels   = False\n",
    "    gl.xlabel_style = {'size':10}\n",
    "    gl.ylabel_style = {'size':10}\n",
    "\n",
    "    # Legend\n",
    "    station_handle = Line2D([],[], marker='o', color='k', linestyle='None', markersize=7, label='Stations')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(station_handle)\n",
    "    labels.append('Stations')\n",
    "    ax.legend(handles=handles, labels=labels, loc='upper right', fontsize=9)\n",
    "\n",
    "    out_fn = os.path.join(output_dir, f\"Map_{metric}.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved metric map => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 7. IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "print(\"\\nCreating the improved Taylor Diagram from metrics ...\")\n",
    "\n",
    "import mpl_toolkits.axisartist.grid_finder as gf\n",
    "import mpl_toolkits.axisartist.floating_axes as fa\n",
    "import matplotlib.projections as mp\n",
    "from matplotlib.projections import PolarAxes\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "\n",
    "class TaylorDiagram(object):\n",
    "    \"\"\"Taylor Diagram with color-coded axes & short station labels. \n",
    "       Adapted from your reference snippet with 'apply_theta_transforms=False' \n",
    "       to avoid Matplotlib 3.9+ deprecation warnings.\"\"\"\n",
    "\n",
    "    def __init__(self, STD, fig=None, rect=111, label='_'):\n",
    "        self.STD = STD\n",
    "\n",
    "        # Use apply_theta_transforms=False to avoid deprecation warnings\n",
    "        tr = PolarAxes.PolarTransform(apply_theta_transforms=False)\n",
    "\n",
    "        # Correlation labels, now formatted with max 2 decimal places\n",
    "        rlocs = np.concatenate(((np.arange(0,1.1,0.1)), [0.95, 0.99]))\n",
    "        tlocs = np.arccos(rlocs)\n",
    "        tf1 = gf.DictFormatter(dict(zip(tlocs, map(lambda x: f\"{x:.2f}\", rlocs))))  # ✅ FIXED FORMAT\n",
    "\n",
    "        # STDev extent\n",
    "        self.smin = 0\n",
    "        self.smax = 2 * self.STD\n",
    "\n",
    "        gh = fa.GridHelperCurveLinear(\n",
    "            tr, extremes=(0, np.pi/2, self.smin, self.smax),\n",
    "            grid_locator1=gf.FixedLocator(tlocs), tick_formatter1=tf1\n",
    "        )\n",
    "\n",
    "        if fig is None:\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "        ax = fa.FloatingSubplot(fig, rect, grid_helper=gh)\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        # Correlation (red, top)\n",
    "        ax.axis['top'].set_axis_direction('bottom')\n",
    "        ax.axis['top'].label.set_text(\"Correlation Coefficient\")\n",
    "        ax.axis['top'].label.set_color(\"red\")\n",
    "        ax.axis['top'].label.set_fontsize(14)\n",
    "        ax.axis['top'].label.set_rotation(180)\n",
    "        ax.axis['top'].label.set_pad(30)\n",
    "        ax.axis['top'].toggle(ticklabels=True, label=True)\n",
    "        ax.axis['top'].major_ticklabels.set_rotation(180)\n",
    "        ax.axis['top'].major_ticklabels.set_pad(2)\n",
    "        ax.axis['top'].major_ticklabels.set_color(\"red\")\n",
    "        ax.axis['top'].line.set_color(\"red\")\n",
    "\n",
    "        # Centered RMSE (blue, left)\n",
    "        ax.axis['left'].set_axis_direction('bottom')\n",
    "        ax.axis['left'].label.set_text(\"Centered RMSE\")\n",
    "        ax.axis['left'].label.set_color(\"blue\")\n",
    "        ax.axis['left'].label.set_fontsize(14)\n",
    "        ax.axis['left'].label.set_pad(20)\n",
    "        ax.axis['left'].toggle(ticklabels=False, label=True)\n",
    "\n",
    "        # Standard Deviation (black, right)\n",
    "        ax.axis['right'].set_axis_direction('top')\n",
    "        ax.axis['right'].label.set_text(\"Standard Deviation\")\n",
    "        ax.axis['right'].label.set_fontsize(14)\n",
    "        ax.axis['right'].toggle(ticklabels=True, label=True)\n",
    "\n",
    "        # Hide bottom\n",
    "        ax.axis['bottom'].set_visible(False)\n",
    "\n",
    "        ax.grid()\n",
    "        self._ax = ax            # Graphical axes\n",
    "        self.ax = ax.get_aux_axes(tr)  # Polar coordinates\n",
    "\n",
    "        # Reference star = Observed\n",
    "        l, = self.ax.plot([0], self.STD, 'k*', ls='', ms=12, label=label)\n",
    "        # Draw STD contour\n",
    "        t = np.linspace(0, np.pi/2, 100)\n",
    "        r = np.zeros_like(t)+self.STD\n",
    "        self.ax.plot(t, r, 'k--', label='_')\n",
    "\n",
    "        self.samplePoints = [l]\n",
    "\n",
    "    def add_sample(self, stdev, corr, *args, **kwargs):\n",
    "        \"\"\"Add a point to the diagram. stdev => radial, corr => angle.\"\"\"\n",
    "        theta = np.arccos(corr)\n",
    "        l, = self.ax.plot(theta, stdev, *args, **kwargs)\n",
    "        self.samplePoints.append(l)\n",
    "        return l\n",
    "\n",
    "    def add_contours(self, levels=5, **kwargs):\n",
    "        \"\"\"Add centered RMSE contours in blue.\"\"\"\n",
    "        import math\n",
    "        rs, ts = np.meshgrid(np.linspace(self.smin, self.smax, 100),\n",
    "                             np.linspace(0, math.pi/2, 100))\n",
    "        rmse = np.sqrt(self.STD**2 + rs**2 - 2*self.STD*rs*np.cos(ts))\n",
    "        cont = self.ax.contour(ts, rs, rmse, levels, colors=\"blue\", **kwargs)\n",
    "        return cont\n",
    "\n",
    "def short_station_name(full_name):\n",
    "    # Return only first word\n",
    "    return full_name.split()[0]\n",
    "\n",
    "def create_taylor_diagram(df, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\"):\n",
    "    \"\"\"Plot the improved Taylor Diagram with color-coded axes, \n",
    "       partial station labels, & top 10% correlation in different color.\"\"\"\n",
    "\n",
    "    # Drop rows missing needed columns\n",
    "    df_td = df.dropna(subset=[ref_col, std_col, corr_col])\n",
    "    if df_td.empty:\n",
    "        print(\"Not enough data for Taylor Diagram.\")\n",
    "        return\n",
    "\n",
    "    # Reference STD is average of the reference col\n",
    "    ref_std_val = df_td[ref_col].mean()\n",
    "    # Determine top 10% correlation\n",
    "    thr_cc = np.percentile(df_td[corr_col].values, 90)\n",
    "\n",
    "    # Prepare diagram\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    dia = TaylorDiagram(ref_std_val, fig=fig, rect=111, label='OBS')\n",
    "    # Add RMSE contours\n",
    "    ctn = dia.add_contours(levels=6)\n",
    "    plt.clabel(ctn, inline=1, fontsize=10)\n",
    "\n",
    "    # We'll color the top-10% correlation samples differently.\n",
    "    # Also show only the first word of station name in legend\n",
    "    norm = Normalize(vmin=0, vmax=len(df_td))\n",
    "    color_map = cm.get_cmap(\"tab20\", len(df_td))\n",
    "\n",
    "    for i, row in enumerate(df_td.itertuples()):\n",
    "        stdev = getattr(row, std_col)\n",
    "        corr  = getattr(row, corr_col)\n",
    "        stn   = getattr(row, stn_name_col)\n",
    "        short_label = short_station_name(stn)\n",
    "\n",
    "        # If correlation >= thr_cc => good performing => let's color them\n",
    "        # else use a default style\n",
    "        if corr >= thr_cc:\n",
    "            # Different color and marker\n",
    "            mk_style = dict(marker='o', ms=6, \n",
    "                            mec=color_map(i), mfc='none', mew=1.6,\n",
    "                            label=short_label)\n",
    "        else:\n",
    "            mk_style = dict(marker='o', ms=4, \n",
    "                            mec='gray', mfc='none', mew=1,\n",
    "                            label='_')  # underscore => not in legend\n",
    "\n",
    "        dia.add_sample(stdev, corr, **mk_style)\n",
    "\n",
    "    # Build legend from the sample points that have label != \"_\"\n",
    "    labels_all = [p.get_label() for p in dia.samplePoints]\n",
    "    handles_all= [p for p in dia.samplePoints]\n",
    "    # Filter out the undesired ones\n",
    "    final_pairs = [(h,l) for (h,l) in zip(handles_all,labels_all) if l!=\"_\"]\n",
    "    if final_pairs:\n",
    "        handles_ok, labels_ok = zip(*final_pairs)\n",
    "        plt.legend(handles_ok, labels_ok, numpoints=1, prop=dict(size=6), \n",
    "                   loc='upper right', title=\"Best CC Grids\")\n",
    "\n",
    "    # Title\n",
    "    dia._ax.set_title(\"Taylor Diagram prism\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    out_fn = os.path.join(output_dir, \"Improved_TaylorDiagram.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved improved Taylor Diagram => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 8. CREATE IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "# We'll use 'STD' as the reference column & std col, 'CC' as correlation\n",
    "# If you have a separate obs STD column, rename above\n",
    "create_taylor_diagram(df_merged, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\")\n",
    "\n",
    "##############################################################################\n",
    "# 9. OUTPUT A “METRICS EVALUATION” TABLE\n",
    "##############################################################################\n",
    "print(\"\\nFinal Metrics Evaluation Table (All Stations):\")\n",
    "cols_for_eval = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "avail_cols = [c for c in cols_for_eval if c in df_merged.columns]\n",
    "eval_table = df_merged[avail_cols].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"])\n",
    "print(eval_table)\n",
    "\n",
    "eval_table_out = os.path.join(output_dir,\"Overall_Metrics_Evaluation.csv\")\n",
    "eval_table.to_csv(eval_table_out)\n",
    "print(f\"Saved overall metrics evaluation => {eval_table_out}\")\n",
    "\n",
    "print(\"\\n✅ Done! Renamed dimension for NetCDF, renamed Index_of_Agreement to 'd', produced improved Taylor Diagram, and exported everything.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287749a-251f-48a6-8edb-60993ce68479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps and Taylor diagram of the statistical metrics for prcp EMDNA\n",
    "# --------------------------------------------------------------------\n",
    "# This version iterates over the 10 requested ensembles:\n",
    "#   1, 11, 21, 31, 41, 51, 61, 71, 81, 91\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import mpl_toolkits.axisartist.grid_finder  as gf\n",
    "import mpl_toolkits.axisartist.floating_axes as fa\n",
    "from   matplotlib.projections import PolarAxes\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# 0.  CONSTANT FILES (shared across ensembles)\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "physical_file  = r\"D:\\PhD\\GLB\\Merged USA and CA\\Entire GLB\\filtered_stations_with_elevation.csv\"\n",
    "shapefile_path = r\"D:\\PhD\\GLB\\greatlakes_subbasins\\New folder\\Great_Lakes.shp\"\n",
    "lakes_shp      = r\"D:\\PhD\\GLB\\greatlakes_subbasins\\GLB_Water_Bodies\\Main_Lakes_GLB.shp\"\n",
    "target_crs     = \"EPSG:4326\"\n",
    "\n",
    "print(\"▶ Loading static inputs (station catalogue & lakes)…\")\n",
    "df_phys = (pd.read_csv(physical_file)\n",
    "           .rename(columns={\"NAME\": \"station_name\",\n",
    "                            \"LATITUDE\": \"lat\",\n",
    "                            \"LONGITUDE\": \"lon\",\n",
    "                            \"Elevation\": \"elev\"}))\n",
    "\n",
    "gdf_lakes = gpd.read_file(shapefile_path)\n",
    "if gdf_lakes.crs is not None:\n",
    "    gdf_lakes = gdf_lakes.to_crs(target_crs)\n",
    "else:\n",
    "    gdf_lakes.crs = target_crs\n",
    "lon_min, lat_min, lon_max, lat_max = gdf_lakes.total_bounds\n",
    "print(\"   Great-Lakes bounds:\", (lon_min, lat_min, lon_max, lat_max))\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# 1.  LOOP OVER ENSEMBLES\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# root folder that contains the 10 ensemble sub-directories\n",
    "root_dir = (r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\"\n",
    "            r\"\\Ensemble files\\EMDNA_GLB_Precipitation\")\n",
    "\n",
    "ENSEMBLES = [1, 11, 21, 31, 41, 51, 61, 71, 81, 91]\n",
    "\n",
    "for ens in ENSEMBLES:\n",
    "    print(\"\\n\" + \"=\" * 79)\n",
    "    print(f\"⧉  Processing ensemble {ens}  ⧉\")\n",
    "    print(\"=\" * 79)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 1-A.  FILE PATHS  (ensemble-specific)\n",
    "    # -----------------------------------------------------------------------\n",
    "    base_dir = os.path.join(root_dir, str(ens))\n",
    "\n",
    "    nc_file = os.path.join(\n",
    "        base_dir, \"daily_loop\",\n",
    "        f\"emdna_vs_stations_25km_LWR_1991_2012_prcp_{ens:03d}.nc\"\n",
    "    )\n",
    "    metrics_csv = os.path.join(\n",
    "        base_dir, \"metrics\",\n",
    "        f\"station_metrics_25km_LWR_EMDNA_1991_2012_prcp_{ens:03d}.csv\"\n",
    "    )\n",
    "\n",
    "    output_dir = os.path.join(base_dir, \"Maps_and_Taylor\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 2.  LOAD NETCDF (RENAME DIM) & METRICS CSV\n",
    "    # -----------------------------------------------------------------------\n",
    "    print(\"Loading EMDNA vs Station NetCDF …\")\n",
    "    if not os.path.isfile(nc_file):\n",
    "        print(f\"   ⚠ NetCDF missing for ensemble {ens}: {nc_file}\")\n",
    "        continue\n",
    "    ds_raw = xr.open_dataset(nc_file)\n",
    "\n",
    "    ds = ds_raw.rename({'station_index': 'station'})\n",
    "    print(\"Dims after rename:\", ds.dims)\n",
    "    print(\"Data vars:\", list(ds.data_vars))\n",
    "\n",
    "    print(\"\\nLoading station-level metrics CSV …\")\n",
    "    if not os.path.isfile(metrics_csv):\n",
    "        print(f\"   ⚠ Metrics CSV missing for ensemble {ens}: {metrics_csv}\")\n",
    "        continue\n",
    "    \n",
    "    df_metrics_all = pd.read_csv(metrics_csv)\n",
    "    # standardise column name\n",
    "    if \"Index_of_Agreement\" in df_metrics_all.columns and \"d\" not in df_metrics_all.columns:\n",
    "        df_metrics_all = df_metrics_all.rename(columns={\"Index_of_Agreement\": \"d\"})\n",
    "    \n",
    "    # ── only one variable (“prcp”) in this workflow ──────────────────────────\n",
    "    metrics_by_var = {\"prcp\": df_metrics_all.copy()}\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 3.  MERGE STATION COORDINATES\n",
    "    # -----------------------------------------------------------------------\n",
    "    print(\"\\nMerging station coordinates …\")\n",
    "    merged_by_var = {}\n",
    "    for var, df_met in metrics_by_var.items():          # var will be \"prcp\"\n",
    "        merged = pd.merge(df_met, df_phys, on=\"station_name\", how=\"inner\")\n",
    "        merged_by_var[var] = merged\n",
    "        print(f\"   {var}: merged {len(merged)} rows\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 4.  BASIC CHECKS ON NETCDF\n",
    "    # -----------------------------------------------------------------------\n",
    "    time_dim    = ds[\"time\"].size\n",
    "    station_dim = ds[\"station\"].size\n",
    "    time_min    = ds[\"time\"].values.min()\n",
    "    time_max    = ds[\"time\"].values.max()\n",
    "    print(f\"\\nNetCDF summary → time steps: {time_dim:,}, stations: {station_dim}\")\n",
    "    print(\"Time span      →\", str(time_min), \"to\", str(time_max))\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 5.  MAP STATISTICAL METRICS WITH HOTSPOTS\n",
    "    # -----------------------------------------------------------------------\n",
    "    metrics_list = [\"MBE\", \"RMSE\", \"STD\", \"CC\", \"d\"]\n",
    "    titles_dict  = { \"MBE\":\"Mean Bias Error (MBE)\",\n",
    "                     \"RMSE\":\"Root Mean Square Error (RMSE)\",\n",
    "                     \"STD\":\"Standard Deviation (STD)\",\n",
    "                     \"CC\":\"Correlation Coefficient (CC)\",\n",
    "                     \"d\":\"Index of Agreement (d)\" }\n",
    "\n",
    "    print(\"\\nGenerating metric maps with hotspots …\")\n",
    "\n",
    "    for var, df_merged in merged_by_var.items():        # only \"prcp\"\n",
    "        for metric in metrics_list:\n",
    "            if metric not in df_merged.columns:\n",
    "                continue\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 8),\n",
    "                                   subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "            ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "\n",
    "            ax.add_feature(cfeature.BORDERS,  linestyle=':')\n",
    "            ax.add_feature(cfeature.LAKES,    alpha=0.4)\n",
    "            ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "            for geom in gdf_lakes.geometry:\n",
    "                ax.add_geometries([geom], ccrs.PlateCarree(),\n",
    "                                  facecolor='none', edgecolor='blue', linewidth=1)\n",
    "\n",
    "            sc = ax.scatter(df_merged[\"lon\"], df_merged[\"lat\"],\n",
    "                            c=df_merged[metric], cmap=\"viridis\", s=60,\n",
    "                            edgecolor=\"k\", transform=ccrs.PlateCarree())\n",
    "            cb = plt.colorbar(sc, ax=ax, shrink=0.8, pad=0.02)\n",
    "            cb.set_label(metric)\n",
    "\n",
    "            plt.title(f\"{var.upper()} – {titles_dict.get(metric, metric)}\")\n",
    "\n",
    "            vals = df_merged[metric].dropna().values\n",
    "            if metric in [\"MBE\", \"RMSE\", \"STD\"]:\n",
    "                thr = np.percentile(vals, 90)\n",
    "                hotspot = df_merged[metric] >= thr\n",
    "            else:\n",
    "                thr = np.percentile(vals, 10)\n",
    "                hotspot = df_merged[metric] <= thr\n",
    "\n",
    "            ax.scatter(df_merged.loc[hotspot, \"lon\"],\n",
    "                       df_merged.loc[hotspot, \"lat\"],\n",
    "                       facecolors='none', edgecolors='red', s=90, linewidths=1.5,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "\n",
    "            gl = ax.gridlines(draw_labels=True, linewidth=0.4,\n",
    "                              linestyle='--', alpha=0.5, color='gray')\n",
    "            gl.right_labels = gl.top_labels = False\n",
    "\n",
    "            out_fn = os.path.join(output_dir, f\"{var}_Map_{metric}.png\")\n",
    "            plt.savefig(out_fn, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"      ↳ saved {out_fn}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 6.  IMPROVED TAYLOR DIAGRAM  (class & helper are **unchanged**)\n",
    "    # -----------------------------------------------------------------------\n",
    "    print(\"\\nCreating the improved Taylor Diagram from metrics …\")\n",
    "\n",
    "    class TaylorDiagram(object):\n",
    "        \"\"\"Taylor diagram with colour-coded axes & short station labels\n",
    "           (identical styling to the original tmean diagram).\"\"\"\n",
    "\n",
    "        def __init__(self, ref_std, fig=None, rect=111, label='OBS'):\n",
    "            self.ref_std = ref_std\n",
    "\n",
    "            tr = PolarAxes.PolarTransform(apply_theta_transforms=False)\n",
    "\n",
    "            rlocs = np.concatenate((np.arange(0, 1.1, 0.1), [0.95, 0.99]))\n",
    "            tlocs = np.arccos(rlocs)\n",
    "            tf1   = gf.DictFormatter(dict(zip(tlocs, [f\"{r:.2f}\" for r in rlocs])))\n",
    "\n",
    "            self.smin, self.smax = 0, 1.6 * ref_std\n",
    "            gh = fa.GridHelperCurveLinear(\n",
    "                tr,\n",
    "                extremes=(0, np.pi/2, self.smin, self.smax),\n",
    "                grid_locator1=gf.FixedLocator(tlocs),\n",
    "                tick_formatter1=tf1\n",
    "            )\n",
    "\n",
    "            if fig is None:\n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "            ax = fa.FloatingSubplot(fig, rect, grid_helper=gh)\n",
    "            fig.add_subplot(ax)\n",
    "\n",
    "            ax.axis['top'   ].set_axis_direction('bottom')\n",
    "            ax.axis['top'   ].label.set_text(\"Correlation Coefficient\")\n",
    "            ax.axis['top'   ].label.set_color(\"red\")\n",
    "            ax.axis['top'   ].label.set_fontsize(14)\n",
    "            ax.axis['top'   ].label.set_rotation(180)\n",
    "            ax.axis['top'   ].label.set_pad(30)\n",
    "            ax.axis['top'   ].toggle(ticklabels=True, label=True)\n",
    "            ax.axis['top'   ].major_ticklabels.set_rotation(180)\n",
    "            ax.axis['top'   ].major_ticklabels.set_color(\"red\")\n",
    "            ax.axis['top'   ].line.set_color(\"red\")\n",
    "\n",
    "            ax.axis['left'  ].set_axis_direction('bottom')\n",
    "            ax.axis['left'  ].label.set_text(\"Centered RMSE\")\n",
    "            ax.axis['left'  ].label.set_color(\"blue\")\n",
    "            ax.axis['left'  ].label.set_fontsize(14)\n",
    "            ax.axis['left'  ].toggle(ticklabels=False, label=True)\n",
    "\n",
    "            ax.axis['right' ].set_axis_direction('top')\n",
    "            ax.axis['right' ].label.set_text(\"Standard Deviation\")\n",
    "            ax.axis['right' ].label.set_fontsize(14)\n",
    "            ax.axis['right' ].toggle(ticklabels=True, label=True)\n",
    "            ax.axis['right' ].major_ticklabels.set_pad(2)\n",
    "            ax.axis['right' ].major_ticklabels.set_fontsize(10)\n",
    "            ax.axis['right' ].major_ticklabels.set_color(\"black\")\n",
    "\n",
    "            ax.axis['bottom'].set_visible(False)\n",
    "            ax.grid()\n",
    "\n",
    "            self._ax = ax\n",
    "            self.ax  = ax.get_aux_axes(tr)\n",
    "\n",
    "            self.ax.plot([0], [ref_std], 'k*', ms=12, label=label)\n",
    "            t = np.linspace(0, np.pi/2, 100)\n",
    "            self.ax.plot(t, np.full_like(t, ref_std), 'k--')\n",
    "\n",
    "            self.samples = []\n",
    "\n",
    "        def add_sample(self, std, corr, **kwargs):\n",
    "            θ = np.arccos(corr)\n",
    "            p, = self.ax.plot(θ, std, **kwargs)\n",
    "            self.samples.append(p)\n",
    "            return p\n",
    "\n",
    "        def add_contours(self, levels=6, **kwargs):\n",
    "            rs, ts = np.meshgrid(np.linspace(self.smin, self.smax, 100),\n",
    "                                 np.linspace(0, math.pi/2, 100))\n",
    "            rmse = np.sqrt(self.ref_std**2 + rs**2\n",
    "                           - 2*self.ref_std*rs*np.cos(ts))\n",
    "            return self.ax.contour(ts, rs, rmse, levels,\n",
    "                                   colors=\"blue\", **kwargs)\n",
    "\n",
    "    def short_name(full):\n",
    "        return full.split()[0]\n",
    "\n",
    "    def create_taylor(df, var):\n",
    "        df_plot = df.dropna(subset=[\"STD\", \"CC\"])\n",
    "        if df_plot.empty:\n",
    "            print(f\"   – no valid data for {var}\")\n",
    "            return\n",
    "\n",
    "        ref_std = df_plot[\"STD\"].mean()\n",
    "        td = TaylorDiagram(ref_std)\n",
    "\n",
    "        cs = td.add_contours(levels=6)\n",
    "        plt.clabel(cs, inline=1, fontsize=9, fmt=\"%.0f\")\n",
    "\n",
    "        thr  = np.percentile(df_plot[\"CC\"], 90)\n",
    "        cmap = cm.get_cmap(\"tab20\", len(df_plot))\n",
    "\n",
    "        for i, row in df_plot.iterrows():\n",
    "            kwargs = dict(marker='o',\n",
    "                          ms   =6 if row[\"CC\"] >= thr else 4,\n",
    "                          mec  =cmap(i) if row[\"CC\"] >= thr else \"gray\",\n",
    "                          mfc  =\"none\",\n",
    "                          mew  =1.6 if row[\"CC\"] >= thr else 1,\n",
    "                          label=short_name(row[\"station_name\"])\n",
    "                                if row[\"CC\"] >= thr else \"_\")\n",
    "            td.add_sample(row[\"STD\"], row[\"CC\"], **kwargs)\n",
    "\n",
    "        handles = [h for h in td.samples if h.get_label() != \"_\"]\n",
    "        labels  = [h.get_label() for h in handles]\n",
    "        if handles:\n",
    "            plt.legend(handles, labels, numpoints=1, prop=dict(size=6),\n",
    "                       loc=\"upper right\", title=\"Best CC Grids\")\n",
    "\n",
    "        td._ax.set_title(f\"Taylor Diagram – EMDNA PRCP  (ensemble {ens})\",\n",
    "                         fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "        out_png = os.path.join(output_dir,\n",
    "                   f\"Improved_TaylorDiagram_{var}.png\")\n",
    "        plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"      ↳ saved {out_png}\")\n",
    "\n",
    "    for var in [\"prcp\"]:\n",
    "        print(f\"• Taylor for {var}\")\n",
    "        create_taylor(merged_by_var[var], var)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # 7.  OUTPUT OVERALL METRICS TABLE\n",
    "    # -----------------------------------------------------------------------\n",
    "    print(\"\\nFinal Metrics Evaluation Table (All Stations – PRCP):\")\n",
    "    combined_df = merged_by_var[\"prcp\"].copy()\n",
    "\n",
    "    cols_for_eval = [\"MBE\", \"RMSE\", \"STD\", \"CC\", \"d\"]\n",
    "    avail_cols    = [c for c in cols_for_eval if c in combined_df.columns]\n",
    "\n",
    "    eval_table = combined_df[avail_cols].agg(\n",
    "                    [\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "    print(eval_table)\n",
    "\n",
    "    eval_table_out = os.path.join(output_dir,\n",
    "                      \"Overall_Metrics_Evaluation.csv\")\n",
    "    eval_table.to_csv(eval_table_out)\n",
    "    print(f\"      ↳ saved overall metrics evaluation => {eval_table_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3145900-08bf-4d16-a98f-5a2806f3932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps and Taylor diagram of the statistical metrics for ERA5 (prcp)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "##############################################################################\n",
    "# 1. FILE PATHS\n",
    "##############################################################################\n",
    "nc_file       = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\ERA5_GLB_Total_Precipitaion\\Modified for prcp\\daily_loop\\era5_vs_stations_8Nearest_LWR_1991_2012.nc\"\n",
    "metrics_csv   = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\ERA5_GLB_Total_Precipitaion\\Modified for prcp\\metrics\\station_metrics_8Nearest_LWR_ERA5_1991_2012.csv\"\n",
    "physical_file = r\"D:\\PhD\\GLB\\Merged USA and CA\\Entire GLB\\filtered_stations_with_elevation.csv\"\n",
    "shapefile_path= r\"D:\\PhD\\GLB\\greatlakes_subbasins\\New folder\\Great_Lakes.shp\"\n",
    "lakes_shp     = r\"D:\\PhD\\GLB\\greatlakes_subbasins\\GLB_Water_Bodies\\Main_Lakes_GLB.shp\"\n",
    "target_crs    = \"EPSG:4326\"  \n",
    "output_dir    = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\ERA5_GLB_Total_Precipitaion\\Modified for prcp\\Maps_and_Taylor2\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "##############################################################################\n",
    "# 2. LOAD NETCDF (RENAME DIMENSION) & METRICS CSV\n",
    "##############################################################################\n",
    "print(\"Loading ERA5 vs Station NetCDF ...\")\n",
    "ds_raw = xr.open_dataset(nc_file)\n",
    "print(\"Original dims in NetCDF:\", ds_raw.dims)\n",
    "\n",
    "# Rename dimension \"variable\" -> \"station\"\n",
    "ds = ds_raw.rename({\"variable\": \"station\"})\n",
    "print(\"\\nAfter renaming => ds.dims:\", ds.dims)\n",
    "print(\"Data variables in NetCDF:\", list(ds.data_vars))\n",
    "\n",
    "print(\"\\nLoading station-level metrics from CSV ...\")\n",
    "df_metrics = pd.read_csv(metrics_csv)\n",
    "print(\"Loaded metrics CSV with columns:\", df_metrics.columns.tolist())\n",
    "\n",
    "# The code uses \"d\" for the Index of Agreement. If your CSV uses \"Index_of_Agreement\",\n",
    "# rename it to \"d\" so references to 'd' won't fail:\n",
    "if \"Index_of_Agreement\" in df_metrics.columns and \"d\" not in df_metrics.columns:\n",
    "    df_metrics = df_metrics.rename(columns={\"Index_of_Agreement\": \"d\"})\n",
    "\n",
    "##############################################################################\n",
    "# 3. LOAD & MERGE STATION COORDINATES\n",
    "##############################################################################\n",
    "print(\"\\nLoading station location info ...\")\n",
    "df_physical = pd.read_csv(physical_file)\n",
    "df_physical = df_physical.rename(columns={\n",
    "    \"NAME\": \"station_name\",\n",
    "    \"LATITUDE\": \"lat\",\n",
    "    \"LONGITUDE\": \"lon\",\n",
    "    \"Elevation\": \"elev\"\n",
    "})\n",
    "\n",
    "# Merge on station_name (assuming it matches)\n",
    "common_col = \"station_name\"\n",
    "if common_col not in df_metrics.columns:\n",
    "    print(f\"WARNING: {common_col} not in df_metrics. Aborting or adjust code.\")\n",
    "    # Might raise an error or do a different approach\n",
    "\n",
    "print(\"\\nMerging metrics with physical station coords ...\")\n",
    "df_merged = pd.merge(df_metrics, df_physical, how=\"inner\", on=common_col)\n",
    "print(f\"Merged shape: {df_merged.shape}\")\n",
    "print(\"Columns:\", df_merged.columns.tolist())\n",
    "\n",
    "##############################################################################\n",
    "# 4. BASIC CHECKS ON NETCDF\n",
    "##############################################################################\n",
    "time_dim = ds[\"time\"].size\n",
    "station_dim = ds[\"station\"].size\n",
    "print(f\"\\nNetCDF: # time steps = {time_dim}, # stations = {station_dim}\")\n",
    "time_min = ds[\"time\"].values.min()\n",
    "time_max = ds[\"time\"].values.max()\n",
    "print(\"Time range in NetCDF =>\", str(time_min), \"to\", str(time_max))\n",
    "\n",
    "##############################################################################\n",
    "# 5. LOAD GREAT LAKES SHAPEFILE\n",
    "##############################################################################\n",
    "print(\"\\nLoading Great Lakes shapefile ...\")\n",
    "gdf_lakes = gpd.read_file(shapefile_path)\n",
    "if gdf_lakes.crs is not None:\n",
    "    gdf_lakes = gdf_lakes.to_crs(target_crs)\n",
    "else:\n",
    "    gdf_lakes.crs = target_crs\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = gdf_lakes.total_bounds\n",
    "print(\"Great Lakes shapefile loaded. Bounds:\", (lon_min, lat_min, lon_max, lat_max))\n",
    "\n",
    "##############################################################################\n",
    "# 6. MAP STATISTICAL METRICS (MBE,RMSE,STD,CC,d) WITH “HOTSPOTS”\n",
    "##############################################################################\n",
    "metrics_list = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "titles_dict  = {\n",
    "    \"MBE\":  \"Mean Bias Error (MBE)\",\n",
    "    \"RMSE\": \"Root Mean Square Error (RMSE)\",\n",
    "    \"STD\":  \"Standard Deviation (STD)\",\n",
    "    \"CC\":   \"Correlation Coefficient (CC)\",\n",
    "    \"d\":    \"Index of Agreement (d)\"\n",
    "}\n",
    "\n",
    "print(\"\\nGenerating metric maps with hotspots ...\")\n",
    "\n",
    "for metric in metrics_list:\n",
    "    if metric not in df_merged.columns:\n",
    "        print(f\"Metric {metric} not found in df_merged. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Base map\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.4)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Plot the Great Lakes boundary\n",
    "    for geom in gdf_lakes.geometry:\n",
    "        ax.add_geometries([geom], ccrs.PlateCarree(), facecolor='none', edgecolor='blue', linewidth=1)\n",
    "\n",
    "    # Plot station metrics\n",
    "    sc = ax.scatter(df_merged[\"lon\"], df_merged[\"lat\"],\n",
    "                    c=df_merged[metric], cmap=\"viridis\", s=60, edgecolor=\"k\",\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    cb = plt.colorbar(sc, ax=ax, shrink=0.8, pad=0.02)\n",
    "    cb.set_label(metric, fontsize=12)\n",
    "\n",
    "    plt.title(f\"Spatial Distribution: {titles_dict.get(metric, metric)}\", fontsize=14)\n",
    "\n",
    "    # Identify hotspots\n",
    "    # For MBE, RMSE, STD => top 10%\n",
    "    # For CC, d => bottom 10%\n",
    "    vals = df_merged[metric].dropna().values\n",
    "    if metric in [\"MBE\",\"RMSE\",\"STD\"]:\n",
    "        thr = np.percentile(vals, 90)\n",
    "        hotspot = df_merged[metric] >= thr\n",
    "        label_txt = f\"Hotspot >= {thr:.2f}\"\n",
    "    else:\n",
    "        thr = np.percentile(vals, 10)\n",
    "        hotspot = df_merged[metric] <= thr\n",
    "        label_txt = f\"Hotspot <= {thr:.2f}\"\n",
    "\n",
    "    ax.scatter(df_merged.loc[hotspot,\"lon\"], df_merged.loc[hotspot,\"lat\"],\n",
    "               facecolors='none', edgecolors='red', s=90, linewidths=1.5,\n",
    "               transform=ccrs.PlateCarree(), label=label_txt)\n",
    "\n",
    "    # Add Lat/Lon gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.right_labels = False\n",
    "    gl.top_labels   = False\n",
    "    gl.xlabel_style = {'size':10}\n",
    "    gl.ylabel_style = {'size':10}\n",
    "\n",
    "    # Legend\n",
    "    station_handle = Line2D([],[], marker='o', color='k', linestyle='None', markersize=7, label='Stations')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(station_handle)\n",
    "    labels.append('Stations')\n",
    "    ax.legend(handles=handles, labels=labels, loc='upper right', fontsize=9)\n",
    "\n",
    "    out_fn = os.path.join(output_dir, f\"Map_{metric}.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved metric map => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 7. IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "print(\"\\nCreating the improved Taylor Diagram from metrics ...\")\n",
    "\n",
    "import mpl_toolkits.axisartist.grid_finder as gf\n",
    "import mpl_toolkits.axisartist.floating_axes as fa\n",
    "import matplotlib.projections as mp\n",
    "from matplotlib.projections import PolarAxes\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# colour-blind-safe axis colours\n",
    "CB_RED  = \"#D55E00\"   # replaces pure red\n",
    "CB_BLUE = \"#0072B2\"   # replaces pure blue\n",
    "\n",
    "class TaylorDiagram(object):\n",
    "    \"\"\"Taylor Diagram with color-coded axes & short station labels. \n",
    "       Adapted from your reference snippet with 'apply_theta_transforms=False' \n",
    "       to avoid Matplotlib 3.9+ deprecation warnings.\"\"\"\n",
    "\n",
    "    def __init__(self, STD, fig=None, rect=111, label='_'):\n",
    "        self.STD = STD\n",
    "\n",
    "        # Use apply_theta_transforms=False to avoid deprecation warnings\n",
    "        tr = PolarAxes.PolarTransform(apply_theta_transforms=False)\n",
    "\n",
    "        # Correlation labels, now formatted with max 2 decimal places\n",
    "        rlocs = np.concatenate(((np.arange(0,1.1,0.1)), [0.95, 0.99]))\n",
    "        tlocs = np.arccos(rlocs)\n",
    "        tf1 = gf.DictFormatter(dict(zip(tlocs, map(lambda x: f\"{x:.2f}\", rlocs))))  # ✅ FIXED FORMAT\n",
    "\n",
    "        # STDev extent\n",
    "        self.smin = 0\n",
    "        self.smax = 1.6 * self.STD\n",
    "\n",
    "        gh = fa.GridHelperCurveLinear(\n",
    "            tr, extremes=(0, np.pi/2, self.smin, self.smax),\n",
    "            grid_locator1=gf.FixedLocator(tlocs), tick_formatter1=tf1\n",
    "        )\n",
    "\n",
    "        if fig is None:\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "        ax = fa.FloatingSubplot(fig, rect, grid_helper=gh)\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        # Correlation (red, top)\n",
    "        ax.axis['top'].set_axis_direction('bottom')\n",
    "        ax.axis['top'].label.set_text(\"Correlation Coefficient\")\n",
    "        ax.axis['top'].label.set_color(CB_RED)\n",
    "        ax.axis['top'].label.set_fontsize(14)\n",
    "        ax.axis['top'].label.set_rotation(180)\n",
    "        ax.axis['top'].label.set_pad(30)\n",
    "        ax.axis['top'].toggle(ticklabels=True, label=True)\n",
    "        ax.axis['top'].major_ticklabels.set_rotation(180)\n",
    "        ax.axis['top'].major_ticklabels.set_pad(2)\n",
    "        ax.axis['top'].major_ticklabels.set_color(CB_RED)\n",
    "        ax.axis['top'].line.set_color(CB_RED)\n",
    "\n",
    "        # Centered RMSE (blue, left)\n",
    "        ax.axis['left'].set_axis_direction('bottom')\n",
    "        ax.axis['left'].label.set_text(\"Centered RMSE\")\n",
    "        ax.axis['left'].label.set_color(CB_BLUE)\n",
    "        ax.axis['left'].label.set_fontsize(14)\n",
    "        ax.axis['left'].label.set_pad(20)\n",
    "        ax.axis['left'].toggle(ticklabels=False, label=True)\n",
    "\n",
    "        # Standard Deviation (black, right)\n",
    "        ax.axis['right'].set_axis_direction('top')\n",
    "        ax.axis['right'].label.set_text(\"Standard Deviation\")\n",
    "        ax.axis['right'].label.set_fontsize(14)\n",
    "        ax.axis['right'].toggle(ticklabels=True, label=True)\n",
    "\n",
    "        # Hide bottom\n",
    "        ax.axis['bottom'].set_visible(False)\n",
    "\n",
    "        ax.grid()\n",
    "        self._ax = ax            # Graphical axes\n",
    "        self.ax = ax.get_aux_axes(tr)  # Polar coordinates\n",
    "\n",
    "        # Reference star = Observed\n",
    "        l, = self.ax.plot([0], self.STD, 'k*', ls='', ms=12, label=label)\n",
    "        # Draw STD contour\n",
    "        t = np.linspace(0, np.pi/2, 100)\n",
    "        r = np.zeros_like(t)+self.STD\n",
    "        self.ax.plot(t, r, 'k--', label='_')\n",
    "\n",
    "        self.samplePoints = [l]\n",
    "\n",
    "    def add_sample(self, stdev, corr, *args, **kwargs):\n",
    "        \"\"\"Add a point to the diagram. stdev => radial, corr => angle.\"\"\"\n",
    "        theta = np.arccos(corr)\n",
    "        l, = self.ax.plot(theta, stdev, *args, **kwargs)\n",
    "        self.samplePoints.append(l)\n",
    "        return l\n",
    "\n",
    "    def add_contours(self, levels=5, **kwargs):\n",
    "        \"\"\"Add centered RMSE contours in blue.\"\"\"\n",
    "        import math\n",
    "        rs, ts = np.meshgrid(np.linspace(self.smin, self.smax, 100),\n",
    "                             np.linspace(0, math.pi/2, 100))\n",
    "        rmse = np.sqrt(self.STD**2 + rs**2 - 2*self.STD*rs*np.cos(ts))\n",
    "        cont = self.ax.contour(ts, rs, rmse, levels, colors=CB_BLUE, **kwargs)\n",
    "        return cont\n",
    "\n",
    "def short_station_name(full_name):\n",
    "    # Return only first word\n",
    "    return full_name.split()[0]\n",
    "\n",
    "def create_taylor_diagram(df, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\"):\n",
    "    \"\"\"Plot the improved Taylor Diagram with color-coded axes, \n",
    "       partial station labels, & top 10% correlation in different color.\"\"\"\n",
    "\n",
    "    # Drop rows missing needed columns\n",
    "    df_td = df.dropna(subset=[ref_col, std_col, corr_col])\n",
    "    if df_td.empty:\n",
    "        print(\"Not enough data for Taylor Diagram.\")\n",
    "        return\n",
    "\n",
    "    # Reference STD is average of the reference col\n",
    "    ref_std_val = df_td[ref_col].mean()\n",
    "    # Determine top 10% correlation\n",
    "    thr_cc = np.percentile(df_td[corr_col].values, 90)\n",
    "\n",
    "    # Prepare diagram\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    dia = TaylorDiagram(ref_std_val, fig=fig, rect=111, label='OBS')\n",
    "    # Add RMSE contours\n",
    "    ctn = dia.add_contours(levels=6)\n",
    "    plt.clabel(ctn, inline=1, fontsize=10)\n",
    "\n",
    "    # We'll color the top-10% correlation samples differently.\n",
    "    # Also show only the first word of station name in legend\n",
    "    norm = Normalize(vmin=0, vmax=len(df_td))\n",
    "    color_map = cm.get_cmap(\"tab20\", len(df_td))\n",
    "\n",
    "    for i, row in enumerate(df_td.itertuples()):\n",
    "        stdev = getattr(row, std_col)\n",
    "        corr  = getattr(row, corr_col)\n",
    "        stn   = getattr(row, stn_name_col)\n",
    "        short_label = short_station_name(stn)\n",
    "\n",
    "        # If correlation >= thr_cc => good performing => let's color them\n",
    "        # else use a default style\n",
    "        if corr >= thr_cc:                      # ← coloured, high-CC group\n",
    "            mk_style = dict(marker='o', ms=6,\n",
    "                            mec=color_map(i), mfc='none', mew=1.6,\n",
    "                            label='_best')      # ← give a private label\n",
    "        else:                                   # ← grey default group\n",
    "            mk_style = dict(marker='o', ms=4,\n",
    "                            mec='gray', mfc='none', mew=1,\n",
    "                            label='_')          # ← suppressed in legend\n",
    "\n",
    "\n",
    "\n",
    "        dia.add_sample(stdev, corr, **mk_style)\n",
    "\n",
    "    # Build legend from the sample points that have label != \"_\"\n",
    "        # ───────── legend: two entries, framed ─────────\n",
    "    handle_all   = Line2D([], [], marker='o', ms=7, mfc='none', mec='gray',\n",
    "                          linestyle='None', label='Grid/Station points')\n",
    "    handle_best  = Line2D([], [], marker='o', ms=8, mfc='none', mec=CB_RED,\n",
    "                          linestyle='None', mew=1.6, label='Top 90% CC Grids')\n",
    "\n",
    "    plt.legend(handles=[handle_all, handle_best],\n",
    "               #title=\"Legend\",\n",
    "               loc='upper right', frameon=True, framealpha=1,\n",
    "               edgecolor='black', fontsize=10)\n",
    "\n",
    "\n",
    "    # Title\n",
    "    dia._ax.set_title(\"ERA5\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    out_fn = os.path.join(output_dir, \"Improved_TaylorDiagram.png\")\n",
    "    plt.savefig(out_fn, dpi=600, bbox_inches='tight', pad_inches=0.20)\n",
    "    plt.close()\n",
    "    print(f\"Saved improved Taylor Diagram => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 8. CREATE IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "# We'll use 'STD' as the reference column & std col, 'CC' as correlation\n",
    "# If you have a separate obs STD column, rename above\n",
    "create_taylor_diagram(df_merged, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\")\n",
    "\n",
    "##############################################################################\n",
    "# 9. OUTPUT A “METRICS EVALUATION” TABLE\n",
    "##############################################################################\n",
    "print(\"\\nFinal Metrics Evaluation Table (All Stations):\")\n",
    "cols_for_eval = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "avail_cols = [c for c in cols_for_eval if c in df_merged.columns]\n",
    "eval_table = df_merged[avail_cols].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"])\n",
    "print(eval_table)\n",
    "\n",
    "eval_table_out = os.path.join(output_dir,\"Overall_Metrics_Evaluation.csv\")\n",
    "eval_table.to_csv(eval_table_out)\n",
    "print(f\"Saved overall metrics evaluation => {eval_table_out}\")\n",
    "\n",
    "print(\"\\n✅ Done! Renamed dimension for NetCDF, renamed Index_of_Agreement to 'd', produced improved Taylor Diagram, and exported everything.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09b1d9-62fa-4988-8eac-9b2a291353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps and Taylor diagram of the statistical metrics for RDRS (prcp)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "##############################################################################\n",
    "# 1. FILE PATHS\n",
    "##############################################################################\n",
    "nc_file       = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\RDRS v2.1_GLB_Precipitation\\daily_loop\\rdrs_vs_stations_25km_LWR_1991_2012.nc\"\n",
    "metrics_csv   = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\RDRS v2.1_GLB_Precipitation\\metrics\\station_metrics_25km_LWR_1991_2012.csv\"\n",
    "physical_file = r\"D:\\PhD\\GLB\\Merged USA and CA\\Entire GLB\\filtered_stations_with_elevation.csv\"\n",
    "shapefile_path= r\"D:\\PhD\\GLB\\greatlakes_subbasins\\New folder\\Great_Lakes.shp\"\n",
    "lakes_shp     = r\"D:\\PhD\\GLB\\greatlakes_subbasins\\GLB_Water_Bodies\\Main_Lakes_GLB.shp\"\n",
    "target_crs    = \"EPSG:4326\"  \n",
    "output_dir    = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\RDRS v2.1_GLB_Precipitation\\Maps_and_Taylor\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "##############################################################################\n",
    "# 2. LOAD NETCDF (RENAME DIMENSION) & METRICS CSV\n",
    "##############################################################################\n",
    "print(\"Loading RDRS vs Station NetCDF ...\")\n",
    "ds_raw = xr.open_dataset(nc_file)\n",
    "print(\"Original dims in NetCDF:\", ds_raw.dims)\n",
    "\n",
    "# Rename dimension \"variable\" -> \"station\"\n",
    "ds = ds_raw.rename({\"variable\": \"station\"})\n",
    "print(\"\\nAfter renaming => ds.dims:\", ds.dims)\n",
    "print(\"Data variables in NetCDF:\", list(ds.data_vars))\n",
    "\n",
    "print(\"\\nLoading station-level metrics from CSV ...\")\n",
    "df_metrics = pd.read_csv(metrics_csv)\n",
    "print(\"Loaded metrics CSV with columns:\", df_metrics.columns.tolist())\n",
    "\n",
    "# The code uses \"d\" for the Index of Agreement. If your CSV uses \"Index_of_Agreement\",\n",
    "# rename it to \"d\" so references to 'd' won't fail:\n",
    "if \"Index_of_Agreement\" in df_metrics.columns and \"d\" not in df_metrics.columns:\n",
    "    df_metrics = df_metrics.rename(columns={\"Index_of_Agreement\": \"d\"})\n",
    "\n",
    "##############################################################################\n",
    "# 3. LOAD & MERGE STATION COORDINATES\n",
    "##############################################################################\n",
    "print(\"\\nLoading station location info ...\")\n",
    "df_physical = pd.read_csv(physical_file)\n",
    "df_physical = df_physical.rename(columns={\n",
    "    \"NAME\": \"station_name\",\n",
    "    \"LATITUDE\": \"lat\",\n",
    "    \"LONGITUDE\": \"lon\",\n",
    "    \"Elevation\": \"elev\"\n",
    "})\n",
    "\n",
    "# Merge on station_name (assuming it matches)\n",
    "common_col = \"station_name\"\n",
    "if common_col not in df_metrics.columns:\n",
    "    print(f\"WARNING: {common_col} not in df_metrics. Aborting or adjust code.\")\n",
    "    # Might raise an error or do a different approach\n",
    "\n",
    "print(\"\\nMerging metrics with physical station coords ...\")\n",
    "df_merged = pd.merge(df_metrics, df_physical, how=\"inner\", on=common_col)\n",
    "print(f\"Merged shape: {df_merged.shape}\")\n",
    "print(\"Columns:\", df_merged.columns.tolist())\n",
    "\n",
    "##############################################################################\n",
    "# 4. BASIC CHECKS ON NETCDF\n",
    "##############################################################################\n",
    "time_dim = ds[\"time\"].size\n",
    "station_dim = ds[\"station\"].size\n",
    "print(f\"\\nNetCDF: # time steps = {time_dim}, # stations = {station_dim}\")\n",
    "time_min = ds[\"time\"].values.min()\n",
    "time_max = ds[\"time\"].values.max()\n",
    "print(\"Time range in NetCDF =>\", str(time_min), \"to\", str(time_max))\n",
    "\n",
    "##############################################################################\n",
    "# 5. LOAD GREAT LAKES SHAPEFILE\n",
    "##############################################################################\n",
    "print(\"\\nLoading Great Lakes shapefile ...\")\n",
    "gdf_lakes = gpd.read_file(shapefile_path)\n",
    "if gdf_lakes.crs is not None:\n",
    "    gdf_lakes = gdf_lakes.to_crs(target_crs)\n",
    "else:\n",
    "    gdf_lakes.crs = target_crs\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = gdf_lakes.total_bounds\n",
    "print(\"Great Lakes shapefile loaded. Bounds:\", (lon_min, lat_min, lon_max, lat_max))\n",
    "\n",
    "##############################################################################\n",
    "# 6. MAP STATISTICAL METRICS (MBE,RMSE,STD,CC,d) WITH “HOTSPOTS”\n",
    "##############################################################################\n",
    "metrics_list = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "titles_dict  = {\n",
    "    \"MBE\":  \"Mean Bias Error (MBE)\",\n",
    "    \"RMSE\": \"Root Mean Square Error (RMSE)\",\n",
    "    \"STD\":  \"Standard Deviation (STD)\",\n",
    "    \"CC\":   \"Correlation Coefficient (CC)\",\n",
    "    \"d\":    \"Index of Agreement (d)\"\n",
    "}\n",
    "\n",
    "print(\"\\nGenerating metric maps with hotspots ...\")\n",
    "\n",
    "for metric in metrics_list:\n",
    "    if metric not in df_merged.columns:\n",
    "        print(f\"Metric {metric} not found in df_merged. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Base map\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.4)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Plot the Great Lakes boundary\n",
    "    for geom in gdf_lakes.geometry:\n",
    "        ax.add_geometries([geom], ccrs.PlateCarree(), facecolor='none', edgecolor='blue', linewidth=1)\n",
    "\n",
    "    # Plot station metrics\n",
    "    sc = ax.scatter(df_merged[\"lon\"], df_merged[\"lat\"],\n",
    "                    c=df_merged[metric], cmap=\"viridis\", s=60, edgecolor=\"k\",\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    cb = plt.colorbar(sc, ax=ax, shrink=0.8, pad=0.02)\n",
    "    cb.set_label(metric, fontsize=12)\n",
    "\n",
    "    plt.title(f\"Spatial Distribution: {titles_dict.get(metric, metric)}\", fontsize=14)\n",
    "\n",
    "    # Identify hotspots\n",
    "    # For MBE, RMSE, STD => top 10%\n",
    "    # For CC, d => bottom 10%\n",
    "    vals = df_merged[metric].dropna().values\n",
    "    if metric in [\"MBE\",\"RMSE\",\"STD\"]:\n",
    "        thr = np.percentile(vals, 90)\n",
    "        hotspot = df_merged[metric] >= thr\n",
    "        label_txt = f\"Hotspot >= {thr:.2f}\"\n",
    "    else:\n",
    "        thr = np.percentile(vals, 10)\n",
    "        hotspot = df_merged[metric] <= thr\n",
    "        label_txt = f\"Hotspot <= {thr:.2f}\"\n",
    "\n",
    "    ax.scatter(df_merged.loc[hotspot,\"lon\"], df_merged.loc[hotspot,\"lat\"],\n",
    "               facecolors='none', edgecolors='red', s=90, linewidths=1.5,\n",
    "               transform=ccrs.PlateCarree(), label=label_txt)\n",
    "\n",
    "    # Add Lat/Lon gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.right_labels = False\n",
    "    gl.top_labels   = False\n",
    "    gl.xlabel_style = {'size':10}\n",
    "    gl.ylabel_style = {'size':10}\n",
    "\n",
    "    # Legend\n",
    "    station_handle = Line2D([],[], marker='o', color='k', linestyle='None', markersize=7, label='Stations')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(station_handle)\n",
    "    labels.append('Stations')\n",
    "    ax.legend(handles=handles, labels=labels, loc='upper right', fontsize=9)\n",
    "\n",
    "    out_fn = os.path.join(output_dir, f\"Map_{metric}.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved metric map => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 7. IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "print(\"\\nCreating the improved Taylor Diagram from metrics ...\")\n",
    "\n",
    "import mpl_toolkits.axisartist.grid_finder as gf\n",
    "import mpl_toolkits.axisartist.floating_axes as fa\n",
    "import matplotlib.projections as mp\n",
    "from matplotlib.projections import PolarAxes\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "\n",
    "class TaylorDiagram(object):\n",
    "    \"\"\"Taylor Diagram with color-coded axes & short station labels. \n",
    "       Adapted from your reference snippet with 'apply_theta_transforms=False' \n",
    "       to avoid Matplotlib 3.9+ deprecation warnings.\"\"\"\n",
    "\n",
    "    def __init__(self, STD, fig=None, rect=111, label='_'):\n",
    "        self.STD = STD\n",
    "\n",
    "        # Use apply_theta_transforms=False to avoid deprecation warnings\n",
    "        tr = PolarAxes.PolarTransform(apply_theta_transforms=False)\n",
    "\n",
    "        # Correlation labels, now formatted with max 2 decimal places\n",
    "        rlocs = np.concatenate(((np.arange(0,1.1,0.1)), [0.95, 0.99]))\n",
    "        tlocs = np.arccos(rlocs)\n",
    "        tf1 = gf.DictFormatter(dict(zip(tlocs, map(lambda x: f\"{x:.2f}\", rlocs))))  # ✅ FIXED FORMAT\n",
    "\n",
    "        # STDev extent\n",
    "        self.smin = 0\n",
    "        self.smax = 1.6 * self.STD\n",
    "\n",
    "        gh = fa.GridHelperCurveLinear(\n",
    "            tr, extremes=(0, np.pi/2, self.smin, self.smax),\n",
    "            grid_locator1=gf.FixedLocator(tlocs), tick_formatter1=tf1\n",
    "        )\n",
    "\n",
    "        if fig is None:\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "        ax = fa.FloatingSubplot(fig, rect, grid_helper=gh)\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        # Correlation (red, top)\n",
    "        ax.axis['top'].set_axis_direction('bottom')\n",
    "        ax.axis['top'].label.set_text(\"Correlation Coefficient\")\n",
    "        ax.axis['top'].label.set_color(\"red\")\n",
    "        ax.axis['top'].label.set_fontsize(14)\n",
    "        ax.axis['top'].label.set_rotation(180)\n",
    "        ax.axis['top'].label.set_pad(30)\n",
    "        ax.axis['top'].toggle(ticklabels=True, label=True)\n",
    "        ax.axis['top'].major_ticklabels.set_rotation(180)\n",
    "        ax.axis['top'].major_ticklabels.set_pad(2)\n",
    "        ax.axis['top'].major_ticklabels.set_color(\"red\")\n",
    "        ax.axis['top'].line.set_color(\"red\")\n",
    "\n",
    "        # Centered RMSE (blue, left)\n",
    "        ax.axis['left'].set_axis_direction('bottom')\n",
    "        ax.axis['left'].label.set_text(\"Centered RMSE\")\n",
    "        ax.axis['left'].label.set_color(\"blue\")\n",
    "        ax.axis['left'].label.set_fontsize(14)\n",
    "        ax.axis['left'].label.set_pad(20)\n",
    "        ax.axis['left'].toggle(ticklabels=False, label=True)\n",
    "\n",
    "        # Standard Deviation (black, right)\n",
    "        ax.axis['right'].set_axis_direction('top')\n",
    "        ax.axis['right'].label.set_text(\"Standard Deviation\")\n",
    "        ax.axis['right'].label.set_fontsize(14)\n",
    "        ax.axis['right'].toggle(ticklabels=True, label=True)\n",
    "\n",
    "        # Hide bottom\n",
    "        ax.axis['bottom'].set_visible(False)\n",
    "\n",
    "        ax.grid()\n",
    "        self._ax = ax            # Graphical axes\n",
    "        self.ax = ax.get_aux_axes(tr)  # Polar coordinates\n",
    "\n",
    "        # Reference star = Observed\n",
    "        l, = self.ax.plot([0], self.STD, 'k*', ls='', ms=12, label=label)\n",
    "        # Draw STD contour\n",
    "        t = np.linspace(0, np.pi/2, 100)\n",
    "        r = np.zeros_like(t)+self.STD\n",
    "        self.ax.plot(t, r, 'k--', label='_')\n",
    "\n",
    "        self.samplePoints = [l]\n",
    "\n",
    "    def add_sample(self, stdev, corr, *args, **kwargs):\n",
    "        \"\"\"Add a point to the diagram. stdev => radial, corr => angle.\"\"\"\n",
    "        theta = np.arccos(corr)\n",
    "        l, = self.ax.plot(theta, stdev, *args, **kwargs)\n",
    "        self.samplePoints.append(l)\n",
    "        return l\n",
    "\n",
    "    def add_contours(self, levels=5, **kwargs):\n",
    "        \"\"\"Add centered RMSE contours in blue.\"\"\"\n",
    "        import math\n",
    "        rs, ts = np.meshgrid(np.linspace(self.smin, self.smax, 100),\n",
    "                             np.linspace(0, math.pi/2, 100))\n",
    "        rmse = np.sqrt(self.STD**2 + rs**2 - 2*self.STD*rs*np.cos(ts))\n",
    "        cont = self.ax.contour(ts, rs, rmse, levels, colors=\"blue\", **kwargs)\n",
    "        return cont\n",
    "\n",
    "def short_station_name(full_name):\n",
    "    # Return only first word\n",
    "    return full_name.split()[0]\n",
    "\n",
    "def create_taylor_diagram(df, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\"):\n",
    "    \"\"\"Plot the improved Taylor Diagram with color-coded axes, \n",
    "       partial station labels, & top 10% correlation in different color.\"\"\"\n",
    "\n",
    "    # Drop rows missing needed columns\n",
    "    df_td = df.dropna(subset=[ref_col, std_col, corr_col])\n",
    "    if df_td.empty:\n",
    "        print(\"Not enough data for Taylor Diagram.\")\n",
    "        return\n",
    "\n",
    "    # Reference STD is average of the reference col\n",
    "    ref_std_val = df_td[ref_col].mean()\n",
    "    # Determine top 10% correlation\n",
    "    thr_cc = np.percentile(df_td[corr_col].values, 90)\n",
    "\n",
    "    # Prepare diagram\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    dia = TaylorDiagram(ref_std_val, fig=fig, rect=111, label='OBS')\n",
    "    # Add RMSE contours\n",
    "    ctn = dia.add_contours(levels=6)\n",
    "    plt.clabel(ctn, inline=1, fontsize=10)\n",
    "\n",
    "    # We'll color the top-10% correlation samples differently.\n",
    "    # Also show only the first word of station name in legend\n",
    "    norm = Normalize(vmin=0, vmax=len(df_td))\n",
    "    color_map = cm.get_cmap(\"tab20\", len(df_td))\n",
    "\n",
    "    for i, row in enumerate(df_td.itertuples()):\n",
    "        stdev = getattr(row, std_col)\n",
    "        corr  = getattr(row, corr_col)\n",
    "        stn   = getattr(row, stn_name_col)\n",
    "        short_label = short_station_name(stn)\n",
    "\n",
    "        # If correlation >= thr_cc => good performing => let's color them\n",
    "        # else use a default style\n",
    "        if corr >= thr_cc:\n",
    "            # Different color and marker\n",
    "            mk_style = dict(marker='o', ms=6, \n",
    "                            mec=color_map(i), mfc='none', mew=1.6,\n",
    "                            label=short_label)\n",
    "        else:\n",
    "            mk_style = dict(marker='o', ms=4, \n",
    "                            mec='gray', mfc='none', mew=1,\n",
    "                            label='_')  # underscore => not in legend\n",
    "\n",
    "        dia.add_sample(stdev, corr, **mk_style)\n",
    "\n",
    "    # Build legend from the sample points that have label != \"_\"\n",
    "    labels_all = [p.get_label() for p in dia.samplePoints]\n",
    "    handles_all= [p for p in dia.samplePoints]\n",
    "    # Filter out the undesired ones\n",
    "    final_pairs = [(h,l) for (h,l) in zip(handles_all,labels_all) if l!=\"_\"]\n",
    "    if final_pairs:\n",
    "        handles_ok, labels_ok = zip(*final_pairs)\n",
    "        plt.legend(handles_ok, labels_ok, numpoints=1, prop=dict(size=6), \n",
    "                   loc='upper right', title=\"Best CC Grids\")\n",
    "\n",
    "    # Title\n",
    "    dia._ax.set_title(\"Taylor Diagram RDRS\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    out_fn = os.path.join(output_dir, \"Improved_TaylorDiagram.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved improved Taylor Diagram => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 8. CREATE IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "# We'll use 'STD' as the reference column & std col, 'CC' as correlation\n",
    "# If you have a separate obs STD column, rename above\n",
    "create_taylor_diagram(df_merged, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\")\n",
    "\n",
    "##############################################################################\n",
    "# 9. OUTPUT A “METRICS EVALUATION” TABLE\n",
    "##############################################################################\n",
    "print(\"\\nFinal Metrics Evaluation Table (All Stations):\")\n",
    "cols_for_eval = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "avail_cols = [c for c in cols_for_eval if c in df_merged.columns]\n",
    "eval_table = df_merged[avail_cols].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"])\n",
    "print(eval_table)\n",
    "\n",
    "eval_table_out = os.path.join(output_dir,\"Overall_Metrics_Evaluation.csv\")\n",
    "eval_table.to_csv(eval_table_out)\n",
    "print(f\"Saved overall metrics evaluation => {eval_table_out}\")\n",
    "\n",
    "print(\"\\n✅ Done! Renamed dimension for NetCDF, renamed Index_of_Agreement to 'd', produced improved Taylor Diagram, and exported everything.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7a912-a3d8-47b2-b82b-3e5beb31d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps and Taylor diagram of the statistical metrics for MERRA-2 (prcp)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "##############################################################################\n",
    "# 1. FILE PATHS\n",
    "##############################################################################\n",
    "nc_file       = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\MERRA2_GLB_Precipitation\\daily_loop\\merra2_vs_stations_12Nearest_LWR_1991_2012.nc\"\n",
    "metrics_csv   = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\MERRA2_GLB_Precipitation\\metrics\\station_metrics_12Nearest_LWR_merra2_1991_2012.csv\"\n",
    "physical_file = r\"D:\\PhD\\GLB\\Merged USA and CA\\Entire GLB\\filtered_stations_with_elevation.csv\"\n",
    "shapefile_path= r\"D:\\PhD\\GLB\\greatlakes_subbasins\\New folder\\Great_Lakes.shp\"\n",
    "lakes_shp     = r\"D:\\PhD\\GLB\\greatlakes_subbasins\\GLB_Water_Bodies\\Main_Lakes_GLB.shp\"\n",
    "target_crs    = \"EPSG:4326\"  \n",
    "output_dir    = r\"D:\\PhD\\GLB\\EMDNA(Historical data)\\Ensembles\\New folder\\Ensemble files\\MERRA2_GLB_Precipitation\\Maps_and_Taylor\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "##############################################################################\n",
    "# 2. LOAD NETCDF (RENAME DIMENSION) & METRICS CSV\n",
    "##############################################################################\n",
    "print(\"Loading MERRA2 vs Station NetCDF ...\")\n",
    "ds_raw = xr.open_dataset(nc_file)\n",
    "print(\"Original dims in NetCDF:\", ds_raw.dims)\n",
    "\n",
    "# Rename dimension \"variable\" -> \"station\"\n",
    "ds = ds_raw.rename({\"variable\": \"station\"})\n",
    "print(\"\\nAfter renaming => ds.dims:\", ds.dims)\n",
    "print(\"Data variables in NetCDF:\", list(ds.data_vars))\n",
    "\n",
    "print(\"\\nLoading station-level metrics from CSV ...\")\n",
    "df_metrics = pd.read_csv(metrics_csv)\n",
    "print(\"Loaded metrics CSV with columns:\", df_metrics.columns.tolist())\n",
    "\n",
    "# The code uses \"d\" for the Index of Agreement. If your CSV uses \"Index_of_Agreement\",\n",
    "# rename it to \"d\" so references to 'd' won't fail:\n",
    "if \"Index_of_Agreement\" in df_metrics.columns and \"d\" not in df_metrics.columns:\n",
    "    df_metrics = df_metrics.rename(columns={\"Index_of_Agreement\": \"d\"})\n",
    "\n",
    "##############################################################################\n",
    "# 3. LOAD & MERGE STATION COORDINATES\n",
    "##############################################################################\n",
    "print(\"\\nLoading station location info ...\")\n",
    "df_physical = pd.read_csv(physical_file)\n",
    "df_physical = df_physical.rename(columns={\n",
    "    \"NAME\": \"station_name\",\n",
    "    \"LATITUDE\": \"lat\",\n",
    "    \"LONGITUDE\": \"lon\",\n",
    "    \"Elevation\": \"elev\"\n",
    "})\n",
    "\n",
    "# Merge on station_name (assuming it matches)\n",
    "common_col = \"station_name\"\n",
    "if common_col not in df_metrics.columns:\n",
    "    print(f\"WARNING: {common_col} not in df_metrics. Aborting or adjust code.\")\n",
    "    # Might raise an error or do a different approach\n",
    "\n",
    "print(\"\\nMerging metrics with physical station coords ...\")\n",
    "df_merged = pd.merge(df_metrics, df_physical, how=\"inner\", on=common_col)\n",
    "print(f\"Merged shape: {df_merged.shape}\")\n",
    "print(\"Columns:\", df_merged.columns.tolist())\n",
    "\n",
    "##############################################################################\n",
    "# 4. BASIC CHECKS ON NETCDF\n",
    "##############################################################################\n",
    "time_dim = ds[\"time\"].size\n",
    "station_dim = ds[\"station\"].size\n",
    "print(f\"\\nNetCDF: # time steps = {time_dim}, # stations = {station_dim}\")\n",
    "time_min = ds[\"time\"].values.min()\n",
    "time_max = ds[\"time\"].values.max()\n",
    "print(\"Time range in NetCDF =>\", str(time_min), \"to\", str(time_max))\n",
    "\n",
    "##############################################################################\n",
    "# 5. LOAD GREAT LAKES SHAPEFILE\n",
    "##############################################################################\n",
    "print(\"\\nLoading Great Lakes shapefile ...\")\n",
    "gdf_lakes = gpd.read_file(shapefile_path)\n",
    "if gdf_lakes.crs is not None:\n",
    "    gdf_lakes = gdf_lakes.to_crs(target_crs)\n",
    "else:\n",
    "    gdf_lakes.crs = target_crs\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = gdf_lakes.total_bounds\n",
    "print(\"Great Lakes shapefile loaded. Bounds:\", (lon_min, lat_min, lon_max, lat_max))\n",
    "\n",
    "##############################################################################\n",
    "# 6. MAP STATISTICAL METRICS (MBE,RMSE,STD,CC,d) WITH “HOTSPOTS”\n",
    "##############################################################################\n",
    "metrics_list = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "titles_dict  = {\n",
    "    \"MBE\":  \"Mean Bias Error (MBE)\",\n",
    "    \"RMSE\": \"Root Mean Square Error (RMSE)\",\n",
    "    \"STD\":  \"Standard Deviation (STD)\",\n",
    "    \"CC\":   \"Correlation Coefficient (CC)\",\n",
    "    \"d\":    \"Index of Agreement (d)\"\n",
    "}\n",
    "\n",
    "print(\"\\nGenerating metric maps with hotspots ...\")\n",
    "\n",
    "for metric in metrics_list:\n",
    "    if metric not in df_merged.columns:\n",
    "        print(f\"Metric {metric} not found in df_merged. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Base map\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.4)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Plot the Great Lakes boundary\n",
    "    for geom in gdf_lakes.geometry:\n",
    "        ax.add_geometries([geom], ccrs.PlateCarree(), facecolor='none', edgecolor='blue', linewidth=1)\n",
    "\n",
    "    # Plot station metrics\n",
    "    sc = ax.scatter(df_merged[\"lon\"], df_merged[\"lat\"],\n",
    "                    c=df_merged[metric], cmap=\"viridis\", s=60, edgecolor=\"k\",\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    cb = plt.colorbar(sc, ax=ax, shrink=0.8, pad=0.02)\n",
    "    cb.set_label(metric, fontsize=12)\n",
    "\n",
    "    plt.title(f\"Spatial Distribution: {titles_dict.get(metric, metric)}\", fontsize=14)\n",
    "\n",
    "    # Identify hotspots\n",
    "    # For MBE, RMSE, STD => top 10%\n",
    "    # For CC, d => bottom 10%\n",
    "    vals = df_merged[metric].dropna().values\n",
    "    if metric in [\"MBE\",\"RMSE\",\"STD\"]:\n",
    "        thr = np.percentile(vals, 90)\n",
    "        hotspot = df_merged[metric] >= thr\n",
    "        label_txt = f\"Hotspot >= {thr:.2f}\"\n",
    "    else:\n",
    "        thr = np.percentile(vals, 10)\n",
    "        hotspot = df_merged[metric] <= thr\n",
    "        label_txt = f\"Hotspot <= {thr:.2f}\"\n",
    "\n",
    "    ax.scatter(df_merged.loc[hotspot,\"lon\"], df_merged.loc[hotspot,\"lat\"],\n",
    "               facecolors='none', edgecolors='red', s=90, linewidths=1.5,\n",
    "               transform=ccrs.PlateCarree(), label=label_txt)\n",
    "\n",
    "    # Add Lat/Lon gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.right_labels = False\n",
    "    gl.top_labels   = False\n",
    "    gl.xlabel_style = {'size':10}\n",
    "    gl.ylabel_style = {'size':10}\n",
    "\n",
    "    # Legend\n",
    "    station_handle = Line2D([],[], marker='o', color='k', linestyle='None', markersize=7, label='Stations')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(station_handle)\n",
    "    labels.append('Stations')\n",
    "    ax.legend(handles=handles, labels=labels, loc='upper right', fontsize=9)\n",
    "\n",
    "    out_fn = os.path.join(output_dir, f\"Map_{metric}.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved metric map => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 7. IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "print(\"\\nCreating the improved Taylor Diagram from metrics ...\")\n",
    "\n",
    "import mpl_toolkits.axisartist.grid_finder as gf\n",
    "import mpl_toolkits.axisartist.floating_axes as fa\n",
    "import matplotlib.projections as mp\n",
    "from matplotlib.projections import PolarAxes\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "\n",
    "class TaylorDiagram(object):\n",
    "    \"\"\"Taylor Diagram with color-coded axes & short station labels. \n",
    "       Adapted from your reference snippet with 'apply_theta_transforms=False' \n",
    "       to avoid Matplotlib 3.9+ deprecation warnings.\"\"\"\n",
    "\n",
    "    def __init__(self, STD, fig=None, rect=111, label='_'):\n",
    "        self.STD = STD\n",
    "\n",
    "        # Use apply_theta_transforms=False to avoid deprecation warnings\n",
    "        tr = PolarAxes.PolarTransform(apply_theta_transforms=False)\n",
    "\n",
    "        # Correlation labels, now formatted with max 2 decimal places\n",
    "        rlocs = np.concatenate(((np.arange(0,1.1,0.1)), [0.95, 0.99]))\n",
    "        tlocs = np.arccos(rlocs)\n",
    "        tf1 = gf.DictFormatter(dict(zip(tlocs, map(lambda x: f\"{x:.2f}\", rlocs))))  # ✅ FIXED FORMAT\n",
    "\n",
    "        # STDev extent\n",
    "        self.smin = 0\n",
    "        self.smax = 1.6 * self.STD\n",
    "\n",
    "        gh = fa.GridHelperCurveLinear(\n",
    "            tr, extremes=(0, np.pi/2, self.smin, self.smax),\n",
    "            grid_locator1=gf.FixedLocator(tlocs), tick_formatter1=tf1\n",
    "        )\n",
    "\n",
    "        if fig is None:\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "        ax = fa.FloatingSubplot(fig, rect, grid_helper=gh)\n",
    "        fig.add_subplot(ax)\n",
    "\n",
    "        # Correlation (red, top)\n",
    "        ax.axis['top'].set_axis_direction('bottom')\n",
    "        ax.axis['top'].label.set_text(\"Correlation Coefficient\")\n",
    "        ax.axis['top'].label.set_color(\"red\")\n",
    "        ax.axis['top'].label.set_fontsize(14)\n",
    "        ax.axis['top'].label.set_rotation(180)\n",
    "        ax.axis['top'].label.set_pad(30)\n",
    "        ax.axis['top'].toggle(ticklabels=True, label=True)\n",
    "        ax.axis['top'].major_ticklabels.set_rotation(180)\n",
    "        ax.axis['top'].major_ticklabels.set_pad(2)\n",
    "        ax.axis['top'].major_ticklabels.set_color(\"red\")\n",
    "        ax.axis['top'].line.set_color(\"red\")\n",
    "\n",
    "        # Centered RMSE (blue, left)\n",
    "        ax.axis['left'].set_axis_direction('bottom')\n",
    "        ax.axis['left'].label.set_text(\"Centered RMSE\")\n",
    "        ax.axis['left'].label.set_color(\"blue\")\n",
    "        ax.axis['left'].label.set_fontsize(14)\n",
    "        ax.axis['left'].label.set_pad(20)\n",
    "        ax.axis['left'].toggle(ticklabels=False, label=True)\n",
    "\n",
    "        # Standard Deviation (black, right)\n",
    "        ax.axis['right'].set_axis_direction('top')\n",
    "        ax.axis['right'].label.set_text(\"Standard Deviation\")\n",
    "        ax.axis['right'].label.set_fontsize(14)\n",
    "        ax.axis['right'].toggle(ticklabels=True, label=True)\n",
    "\n",
    "        # Hide bottom\n",
    "        ax.axis['bottom'].set_visible(False)\n",
    "\n",
    "        ax.grid()\n",
    "        self._ax = ax            # Graphical axes\n",
    "        self.ax = ax.get_aux_axes(tr)  # Polar coordinates\n",
    "\n",
    "        # Reference star = Observed\n",
    "        l, = self.ax.plot([0], self.STD, 'k*', ls='', ms=12, label=label)\n",
    "        # Draw STD contour\n",
    "        t = np.linspace(0, np.pi/2, 100)\n",
    "        r = np.zeros_like(t)+self.STD\n",
    "        self.ax.plot(t, r, 'k--', label='_')\n",
    "\n",
    "        self.samplePoints = [l]\n",
    "\n",
    "    def add_sample(self, stdev, corr, *args, **kwargs):\n",
    "        \"\"\"Add a point to the diagram. stdev => radial, corr => angle.\"\"\"\n",
    "        theta = np.arccos(corr)\n",
    "        l, = self.ax.plot(theta, stdev, *args, **kwargs)\n",
    "        self.samplePoints.append(l)\n",
    "        return l\n",
    "\n",
    "    def add_contours(self, levels=5, **kwargs):\n",
    "        \"\"\"Add centered RMSE contours in blue.\"\"\"\n",
    "        import math\n",
    "        rs, ts = np.meshgrid(np.linspace(self.smin, self.smax, 100),\n",
    "                             np.linspace(0, math.pi/2, 100))\n",
    "        rmse = np.sqrt(self.STD**2 + rs**2 - 2*self.STD*rs*np.cos(ts))\n",
    "        cont = self.ax.contour(ts, rs, rmse, levels, colors=\"blue\", **kwargs)\n",
    "        return cont\n",
    "\n",
    "def short_station_name(full_name):\n",
    "    # Return only first word\n",
    "    return full_name.split()[0]\n",
    "\n",
    "def create_taylor_diagram(df, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\"):\n",
    "    \"\"\"Plot the improved Taylor Diagram with color-coded axes, \n",
    "       partial station labels, & top 10% correlation in different color.\"\"\"\n",
    "\n",
    "    # Drop rows missing needed columns\n",
    "    df_td = df.dropna(subset=[ref_col, std_col, corr_col])\n",
    "    if df_td.empty:\n",
    "        print(\"Not enough data for Taylor Diagram.\")\n",
    "        return\n",
    "\n",
    "    # Reference STD is average of the reference col\n",
    "    ref_std_val = df_td[ref_col].mean()\n",
    "    # Determine top 10% correlation\n",
    "    thr_cc = np.percentile(df_td[corr_col].values, 90)\n",
    "\n",
    "    # Prepare diagram\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    dia = TaylorDiagram(ref_std_val, fig=fig, rect=111, label='OBS')\n",
    "    # Add RMSE contours\n",
    "    ctn = dia.add_contours(levels=6)\n",
    "    plt.clabel(ctn, inline=1, fontsize=10)\n",
    "\n",
    "    # We'll color the top-10% correlation samples differently.\n",
    "    # Also show only the first word of station name in legend\n",
    "    norm = Normalize(vmin=0, vmax=len(df_td))\n",
    "    color_map = cm.get_cmap(\"tab20\", len(df_td))\n",
    "\n",
    "    for i, row in enumerate(df_td.itertuples()):\n",
    "        stdev = getattr(row, std_col)\n",
    "        corr  = getattr(row, corr_col)\n",
    "        stn   = getattr(row, stn_name_col)\n",
    "        short_label = short_station_name(stn)\n",
    "\n",
    "        # If correlation >= thr_cc => good performing => let's color them\n",
    "        # else use a default style\n",
    "        if corr >= thr_cc:\n",
    "            # Different color and marker\n",
    "            mk_style = dict(marker='o', ms=6, \n",
    "                            mec=color_map(i), mfc='none', mew=1.6,\n",
    "                            label=short_label)\n",
    "        else:\n",
    "            mk_style = dict(marker='o', ms=4, \n",
    "                            mec='gray', mfc='none', mew=1,\n",
    "                            label='_')  # underscore => not in legend\n",
    "\n",
    "        dia.add_sample(stdev, corr, **mk_style)\n",
    "\n",
    "    # Build legend from the sample points that have label != \"_\"\n",
    "    labels_all = [p.get_label() for p in dia.samplePoints]\n",
    "    handles_all= [p for p in dia.samplePoints]\n",
    "    # Filter out the undesired ones\n",
    "    final_pairs = [(h,l) for (h,l) in zip(handles_all,labels_all) if l!=\"_\"]\n",
    "    if final_pairs:\n",
    "        handles_ok, labels_ok = zip(*final_pairs)\n",
    "        plt.legend(handles_ok, labels_ok, numpoints=1, prop=dict(size=6), \n",
    "                   loc='upper right', title=\"Best CC Grids\")\n",
    "\n",
    "    # Title\n",
    "    dia._ax.set_title(\"Taylor Diagram MERRA2\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    out_fn = os.path.join(output_dir, \"Improved_TaylorDiagram.png\")\n",
    "    plt.savefig(out_fn, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved improved Taylor Diagram => {out_fn}\")\n",
    "\n",
    "##############################################################################\n",
    "# 8. CREATE IMPROVED TAYLOR DIAGRAM\n",
    "##############################################################################\n",
    "# We'll use 'STD' as the reference column & std col, 'CC' as correlation\n",
    "# If you have a separate obs STD column, rename above\n",
    "create_taylor_diagram(df_merged, ref_col=\"STD\", std_col=\"STD\", corr_col=\"CC\", stn_name_col=\"station_name\")\n",
    "\n",
    "##############################################################################\n",
    "# 9. OUTPUT A “METRICS EVALUATION” TABLE\n",
    "##############################################################################\n",
    "print(\"\\nFinal Metrics Evaluation Table (All Stations):\")\n",
    "cols_for_eval = [\"MBE\",\"RMSE\",\"STD\",\"CC\",\"d\"]\n",
    "avail_cols = [c for c in cols_for_eval if c in df_merged.columns]\n",
    "eval_table = df_merged[avail_cols].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"])\n",
    "print(eval_table)\n",
    "\n",
    "eval_table_out = os.path.join(output_dir,\"Overall_Metrics_Evaluation.csv\")\n",
    "eval_table.to_csv(eval_table_out)\n",
    "print(f\"Saved overall metrics evaluation => {eval_table_out}\")\n",
    "\n",
    "print(\"\\n✅ Done! Renamed dimension for NetCDF, renamed Index_of_Agreement to 'd', produced improved Taylor Diagram, and exported everything.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
